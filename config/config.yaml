# COCONUT Configuration

Dataset:
  train_set_file: /content/drive/MyDrive/Îç∞Ïù¥ÌÑ∞ÏÖã/train_BJTU.txt
  test_set_file: /content/drive/MyDrive/Îç∞Ïù¥ÌÑ∞ÏÖã/test_BJTU.txt
  height: 128
  width: 128
  channels: 1
  augmentation: true
  negative_samples_file: /content/drive/MyDrive/Îç∞Ïù¥ÌÑ∞ÏÖã/train_IITD.txt
  num_negative_classes: 100

Model:
  architecture: ccnet
  competition_weight: 0.8
  use_pretrained: true
  pretrained_path: /content/drive/MyDrive/tongji.pth
  # Projection head settings
  projection_dim: 512  # üçë 6144D -> 512D projection
  use_projection: true
  use_projection_for_ncm: false  # üçë NCMÎèÑ 512D projection ÏÇ¨Ïö©Ìï†ÏßÄ (false=6144D, true=512D)

Training:
  experience_batch_size: 16
  memory_batch_size: 112
  num_experiences: 100
  memory_size: 1000
  min_samples_per_class: 9

  # Herding buffer settings (iCaRL-inspired)
  use_herding: false  # Enable herding buffer instead of random sampling
  max_samples_per_class: 20  # Maximum samples per class for herding
  herding_batch_size: 32  # Batch size for feature extraction
  drift_threshold: 0.5  # Threshold for feature drift detection

  epochs_per_experience: 5
  iterations_per_epoch: 10
  num_workers: 8
  learning_rate: 0.000001
  projection_learning_rate: 0.000005  # 5x backbone LR
  scheduler_step_size: 50
  scheduler_gamma: 0.8
  temperature: 0.07  # SupConLoss temperature
  test_interval: 5  # Evaluation and calibration frequency
  checkpoint_path: /content/drive/MyDrive/coconut
  results_path: /content/drive/MyDrive/coconut
  gpu_ids: "0"
  ncm_momentum: 1.0
  seed: 42


  # ProxyAnchorLoss settings
  use_proxy_anchor: true
  proxy_margin: 0.1        # Proxy Anchor margin delta
  proxy_alpha: 16          # Proxy Anchor scaling alpha
  proxy_lr_ratio: 1        # Proxy learning rate multiplier (10x backbone)
  proxy_lambda: 0.7        # Fixed weight (0.3 = 30% ProxyAnchor, 70% SupCon)

# Open-set recognition settings
Openset:
  enabled: true

  # Threshold settings
  threshold_mode: 'far'      # 'eer' or 'far'
  target_far: 0.001           # FAR target 1%
  threshold_alpha: 0.8       # EMA smoothing coefficient
  threshold_max_delta: 1.0  # Maximum change limit

  # Initial values and warmup
  warmup_users: 10           # Warmup period
  initial_tau: 0.5           # Initial threshold

  # Data split
  dev_ratio: 0.1             # Dev set ratio

  # Logging
  verbose_calibration: true  # Verbose output

  # TTA settings (Test-Time Augmentation)
  tta_n_views: 3  # 1=disabled, 2-3 recommended
  tta_include_original: true  # Include original recommended
  tta_agree_k: 0  # 0=auto majority, 2=2+ agreement
  tta_augmentation_strength: 1.0  # 0.3-0.7 recommended
  tta_aggregation: 'mean'  # 'median' or 'mean'

  # Type-specific TTA repeat settings
  tta_n_repeats_genuine: 3      # Genuine scores: 3 repeats (accuracy important)
  tta_n_repeats_between: 3      # Between impostor: 3 repeats (balanced)
  tta_repeat_aggregation: 'mean'  # Inter-repeat aggregation method
  tta_verbose: true  # TTA debugging output

  # Impostor score settings
  impostor_ratio_between: 1.0    # Between impostor 100%
  impostor_balance_total: 6000   # Total samples for balancing

# Negative sample settings
Negative:
  warmup_experiences: 3
  max_per_batch: 1
  r0: 0.5
