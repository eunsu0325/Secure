# config/config.py
import dataclasses
from pathlib import Path
from typing import Optional, Dict

@dataclasses.dataclass
class Dataset:
    train_set_file: Path
    test_set_file: Path
    height: int
    width: int
    channels: int
    augmentation: bool
    negative_samples_file: Path
    num_negative_classes: int

@dataclasses.dataclass
class Model:
    architecture: str
    competition_weight: float
    use_pretrained: bool = False
    pretrained_path: Optional[Path] = None
    # ğŸ§€ í”„ë¡œì ì…˜ í—¤ë“œ ì„¤ì • ì¶”ê°€
    use_projection: bool = True
    projection_dim: int = 128  # ì¶œë ¥ ì°¨ì›ë§Œ ì¡°ì ˆ ê°€ëŠ¥

@dataclasses.dataclass
class Training:
    scr_batch_size: int
    memory_batch_size: int
    num_experiences: int
    memory_size: int
    min_samples_per_class: int
    scr_epochs: int
    iterations_per_epoch: int
    num_epochs: int
    num_workers: int
    learning_rate: float
    scheduler_step_size: int
    scheduler_gamma: float
    temperature: float
    save_interval: int
    test_interval: int
    checkpoint_path: Path
    results_path: Path
    gpu_ids: str
    ncm_momentum: float
    batch_size: int = 128
    seed: int = 42  # ğŸ¥© ì¶”ê°€!
    
    # ğŸ’ ProxyContrastLoss ì„¤ì • ì¶”ê°€
    use_proxy_loss: bool = True
    proxy_lambda: float = 0.3
    proxy_temperature: float = 0.15  # SupConë³´ë‹¤ ë†’ê²Œ!
    proxy_topk: int = 30
    proxy_full_until: int = 100
    proxy_warmup_classes: int = 5
    
    # ğŸ’ Lambda ìŠ¤ì¼€ì¤„ë§ (Optional)
    proxy_lambda_schedule: Optional[Dict[str, float]] = None
    
    # ğŸ’ ì»¤ë²„ë¦¬ì§€ ìƒ˜í”Œë§ ì„¤ì •
    use_coverage_sampling: bool = True
    coverage_k_per_class: int = 2
    
    # ğŸ’ í”„ë¡œí† íƒ€ì… ì„¤ì •
    prototype_beta: float = 0.05  # EMA ê³„ìˆ˜ (í˜„ì¬ëŠ” ë¯¸ì‚¬ìš©)
    
    # â­ï¸ ì—ë„ˆì§€ ìŠ¤ì½”ì–´ ì„¤ì • ì¶”ê°€
    use_energy_score: bool = False
    energy_temperature: float = 0.15
    energy_k_mode: str = 'sqrt'  # 'sqrt', 'fixed', 'log'
    energy_k_fixed: int = 10
    
    def __post_init__(self):
        """ğŸ’ Lambda ìŠ¤ì¼€ì¤„ ê¸°ë³¸ê°’ ì„¤ì •"""
        if self.proxy_lambda_schedule is None and self.use_proxy_loss:
            self.proxy_lambda_schedule = {
                'warmup': 0.1,
                'warmup_10': 0.2,
                'warmup_20': 0.3
            }

@dataclasses.dataclass
class Openset:
    enabled: bool = True
    warmup_users: int = 10
    initial_tau: float = 0.7
    
    # ğŸ í†µì¼ëœ ì„ê³„ì¹˜ íŒŒë¼ë¯¸í„°
    threshold_mode: str = 'far'           # 'eer' or 'far'
    target_far: float = 0.01              # FAR íƒ€ê²Ÿ (1%)
    threshold_alpha: float = 0.2          # EMA ê³„ìˆ˜ (ê¸°ì¡´ smoothing_alpha)
    threshold_max_delta: float = 0.03     # ìµœëŒ€ ë³€í™”í­ (ê¸°ì¡´ max_delta)
    
    dev_ratio: float = 0.2
    negref_max_eval: int = 5000
    
    # â­ï¸ ìŠ¤ì½”ì–´ ëª¨ë“œ ì¶”ê°€
    score_mode: str = 'energy'  # 'max' or 'energy'
    
    # ğŸ ì¶”ê°€ ì˜µì…˜
    verbose_calibration: bool = True      # ìƒì„¸ ì¶œë ¥
    
    # ğŸ¥© TTA (Test-Time Augmentation) ì„¤ì • ì¶”ê°€
    tta_n_views: int = 1  # 1ì´ë©´ ë¹„í™œì„±í™”, 2~3 ê¶Œì¥
    tta_include_original: bool = True  # ì›ë³¸ í¬í•¨ ì—¬ë¶€
    tta_agree_k: int = 0  # 0ì´ë©´ ê³¼ë°˜ ìë™ ê³„ì‚°
    tta_augmentation_strength: float = 0.5  # ì¦ê°• ê°•ë„ (0.0~1.0)
    tta_aggregation: str = 'median'  # 'median' or 'mean' for scores
    
    # ğŸ« TTA ë°˜ë³µ ì„¤ì • ì¶”ê°€
    tta_n_repeats: int = 1  # TTA ë°˜ë³µ íšŸìˆ˜ (ê¸°ë³¸ê°’ 1)
    tta_repeat_aggregation: str = 'median'  # ë°˜ë³µ ê°„ ì§‘ê³„ ë°©ë²• 'median' or 'mean'
    tta_verbose: bool = False  # TTA ë””ë²„ê¹… ì¶œë ¥

@dataclasses.dataclass
class Negative:
    warmup_experiences: int = 4
    max_per_batch: int = 1
    r0: float = 0.5
    base_id: int = 1