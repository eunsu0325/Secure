# config/config.py
import dataclasses
from pathlib import Path
from typing import Optional, Dict

@dataclasses.dataclass
class Dataset:
    train_set_file: Path
    test_set_file: Path
    height: int
    width: int
    channels: int
    augmentation: bool
    negative_samples_file: Path
    num_negative_classes: int

@dataclasses.dataclass
class Model:
    architecture: str
    competition_weight: float
    use_pretrained: bool = False
    pretrained_path: Optional[Path] = None
    # í”„ë¡œì ì…˜ í—¤ë“œ ì„¤ì • ì¶”ê°€
    use_projection: bool = True
    projection_dim: int = 128  # ì¶œë ¥ ì°¨ì›ë§Œ ì¡°ì ˆ ê°€ëŠ¥
    use_projection_for_ncm: bool = False  # ðŸ‘ NCMë„ 512D projection ì‚¬ìš©í• ì§€ (false=6144D, true=512D)

@dataclasses.dataclass
class Training:
    # ê¸°ë³¸ê°’ì´ ì—†ëŠ” í•„ìˆ˜ í•„ë“œë“¤
    experience_batch_size: int
    memory_batch_size: int
    num_experiences: int
    memory_size: int
    min_samples_per_class: int
    epochs_per_experience: int
    iterations_per_epoch: int
    num_workers: int
    learning_rate: float
    scheduler_step_size: int
    scheduler_gamma: float
    temperature: float
    test_interval: int
    checkpoint_path: Path
    results_path: Path
    gpu_ids: str
    ncm_momentum: float

    # ê¸°ë³¸ê°’ì´ ìžˆëŠ” ì„ íƒì  í•„ë“œë“¤
    projection_learning_rate: float = 0.0005  # í”„ë¡œì ì…˜ í—¤ë“œ í•™ìŠµë¥ 
    batch_size: int = 128
    seed: int = 42  # ì¶”ê°€!

    # ProxyAnchorLoss ì„¤ì • ì¶”ê°€
    use_proxy_anchor: bool = True
    proxy_margin: float = 0.1        # Proxy Anchor margin Î´
    proxy_alpha: float = 32          # Proxy Anchor scaling Î±
    proxy_lr_ratio: float = 10       # í”„ë¡ì‹œ í•™ìŠµë¥  ë°°ìˆ˜
    proxy_lambda: float = 0.3        # ê³ ì • ê°€ì¤‘ì¹˜ (SupCon: 0.7, ProxyAnchor: 0.3)

    # Herding buffer ì„¤ì •
    use_herding: bool = False  # Herding buffer ì‚¬ìš© ì—¬ë¶€
    max_samples_per_class: int = 20  # Herding ì‹œ í´ëž˜ìŠ¤ë‹¹ ìµœëŒ€ ìƒ˜í”Œ ìˆ˜
    herding_batch_size: int = 32  # Feature extraction ë°°ì¹˜ í¬ê¸°
    drift_threshold: float = 0.5  # Feature drift ê°ì§€ ìž„ê³„ê°’

@dataclasses.dataclass
class Openset:
    enabled: bool = True
    warmup_users: int = 10
    initial_tau: float = 0.7
    
    # í†µì¼ëœ ìž„ê³„ì¹˜ íŒŒë¼ë¯¸í„°
    threshold_mode: str = 'far'           # 'eer' or 'far'
    target_far: float = 0.01              # FAR íƒ€ê²Ÿ (1%)
    threshold_alpha: float = 0.2          # EMA ê³„ìˆ˜ (ê¸°ì¡´ smoothing_alpha)
    threshold_max_delta: float = 0.03     # ìµœëŒ€ ë³€í™”í­ (ê¸°ì¡´ max_delta)
    
    dev_ratio: float = 0.2

    # ì¶”ê°€ ì˜µì…˜
    verbose_calibration: bool = True      # ìƒì„¸ ì¶œë ¥
    
    # TTA (Test-Time Augmentation) ì„¤ì • ì¶”ê°€
    tta_n_views: int = 1  # 1ì´ë©´ ë¹„í™œì„±í™”, 2~3 ê¶Œìž¥
    tta_include_original: bool = True  # ì›ë³¸ í¬í•¨ ì—¬ë¶€
    tta_agree_k: int = 0  # 0ì´ë©´ ê³¼ë°˜ ìžë™ ê³„ì‚°
    tta_augmentation_strength: float = 0.5  # ì¦ê°• ê°•ë„ (0.0~1.0)
    tta_aggregation: str = 'median'  # 'median' or 'mean' for scores
    
    # TTA ë°˜ë³µ ì„¤ì •
    tta_n_repeats: int = 1  # ì „ì²´ ê¸°ë³¸ê°’ (íƒ€ìž…ë³„ ì„¤ì •ì´ ì—†ì„ ë•Œ ì‚¬ìš©)
    tta_repeat_aggregation: str = 'median'  # ë°˜ë³µ ê°„ ì§‘ê³„ ë°©ë²•
    tta_verbose: bool = False  # TTA ë””ë²„ê¹… ì¶œë ¥
    
    # íƒ€ìž…ë³„ ë…ë¦½ì ì¸ TTA ë°˜ë³µ ì„¤ì • ì¶”ê°€
    tta_n_repeats_genuine: Optional[int] = None      # Genuine ì ìˆ˜ìš©
    tta_n_repeats_between: Optional[int] = None      # Between impostorìš©
    
    # Impostor ì ìˆ˜ ë¹„ìœ¨ ì„¤ì • ì¶”ê°€
    impostor_ratio_between: float = 1.0   # Between impostor ë¹„ìœ¨ (100%)
    impostor_balance_total: int = 6000    # ê· í˜• ë§žì¶œ ì´ ìƒ˜í”Œ ìˆ˜
    
    def __post_init__(self):
        """íƒ€ìž…ë³„ ë°˜ë³µ ì„¤ì •ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©"""
        # Genuine: ê¸°ë³¸ê°’ ì‚¬ìš©
        if self.tta_n_repeats_genuine is None:
            self.tta_n_repeats_genuine = self.tta_n_repeats
        
        # Between: ê¸°ë³¸ê°’ ì‚¬ìš©
        if self.tta_n_repeats_between is None:
            self.tta_n_repeats_between = self.tta_n_repeats
        
        # Between ratio validation (should be 1.0)
        if abs(self.impostor_ratio_between - 1.0) > 1e-6:
            self.impostor_ratio_between = 1.0  # Force to 100%

@dataclasses.dataclass
class Negative:
    warmup_experiences: int = 4
    max_per_batch: int = 1
    r0: float = 0.5
    base_id: int = 1