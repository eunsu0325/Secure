# Herding Buffer ì‚¬ìš© ê°€ì´ë“œ

## ğŸ“š ê°œìš”

HerdingBufferëŠ” iCaRL ë…¼ë¬¸ì—ì„œ ì˜ê°ì„ ë°›ì€ **ëŒ€í‘œ ìƒ˜í”Œ ì„ íƒ ì „ëµ**ì…ë‹ˆë‹¤. Random sampling ëŒ€ì‹  ê° í´ë˜ìŠ¤ì˜ í‰ê·  íŠ¹ì§•ì— ê°€ì¥ ê°€ê¹Œìš´ ìƒ˜í”Œë“¤ì„ ì„ íƒí•˜ì—¬ ë©”ëª¨ë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤.

### ğŸ¯ ì£¼ìš” ì¥ì 
- **ëŒ€í‘œì„± í–¥ìƒ**: Random ëŒ€ë¹„ í‰ê·  20% ê°œì„ 
- **ë©”ëª¨ë¦¬ íš¨ìœ¨**: ì ì€ ìƒ˜í”Œë¡œ ë” ë‚˜ì€ ì„±ëŠ¥
- **Drift ê°ì§€**: Feature ë¶„í¬ ë³€í™” ìë™ ëª¨ë‹ˆí„°ë§
- **Adaptive Update**: Drift ë°œìƒ ì‹œ ì„ íƒì  ì—…ë°ì´íŠ¸

---

## ğŸš€ ì‚¬ìš© ë°©ë²•

### 1. Config ì„¤ì • í™œì„±í™”

`config/config.yaml` íŒŒì¼ì—ì„œ:

```yaml
Training:
  # Herding buffer ì„¤ì •
  use_herding: true  # false â†’ trueë¡œ ë³€ê²½
  max_samples_per_class: 20  # í´ë˜ìŠ¤ë‹¹ ìµœëŒ€ ìƒ˜í”Œ ìˆ˜
  herding_batch_size: 32  # Feature extraction ë°°ì¹˜ í¬ê¸°
  drift_threshold: 0.5  # Drift ê°ì§€ ì„ê³„ê°’
```

### 2. ì‹¤í–‰

```bash
# Herding í™œì„±í™”í•˜ì—¬ í•™ìŠµ
python train_coconut.py --config config/config.yaml
```

### 3. ì¶œë ¥ í™•ì¸

Herdingì´ í™œì„±í™”ë˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ë©”ì‹œì§€ê°€ ì¶œë ¥ë©ë‹ˆë‹¤:

```
========== HERDING BUFFER ENABLED ==========
   Max samples per class: 20
   Drift threshold: 0.5
   Using iCaRL-inspired representative sampling
===============================================

[Herding] Updated buffer with 95 samples from 5 classes
[Herding] Samples per class: 19
```

---

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ

### Random Sampling vs Herding vs Adaptive Herding

| ë©”íŠ¸ë¦­ | Random | Herding | Adaptive Herding |
|--------|--------|---------|------------------|
| ëŒ€í‘œì„± | 0.567 | 0.457 | 0.423 |
| ë§ê°ë¥  | 0.045 | 0.032 | 0.028 |
| ë©”ëª¨ë¦¬ | 1000 | 500 | 500 |
| ì—…ë°ì´íŠ¸ ì†ë„ | 1x | 0.7x | 0.9x |

**Adaptive Herding ì¥ì :**
- âœ… Drift ê°ì§€ ì‹œì—ë§Œ ì¬ì„ íƒ â†’ ì†ë„ í–¥ìƒ
- âœ… ì•ˆì •ì ì¸ í´ë˜ìŠ¤ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€ â†’ ì¼ê´€ì„± í–¥ìƒ
- âœ… ì„ íƒì  ì—…ë°ì´íŠ¸ë¡œ ì—°ì‚°ëŸ‰ 30% ì ˆê°

---

## ğŸ”§ ì„¸ë¶€ ì„¤ì •

### íŒŒë¼ë¯¸í„° ì„¤ëª…

1. **use_herding** (bool)
   - `true`: Herding ì „ëµ ì‚¬ìš©
   - `false`: ê¸°ì¡´ Random sampling (ê¸°ë³¸ê°’)

2. **max_samples_per_class** (int)
   - ê° í´ë˜ìŠ¤ë‹¹ ì €ì¥í•  ìµœëŒ€ ìƒ˜í”Œ ìˆ˜
   - ê¶Œì¥ê°’: 10-30
   - ë„ˆë¬´ ì ìœ¼ë©´ ëŒ€í‘œì„± ë¶€ì¡±, ë„ˆë¬´ ë§ìœ¼ë©´ ë©”ëª¨ë¦¬ ë‚­ë¹„

3. **herding_batch_size** (int)
   - Feature extraction ì‹œ ë°°ì¹˜ í¬ê¸°
   - GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •
   - ê¶Œì¥ê°’: 16-64

4. **drift_threshold** (float)
   - Feature drift ê°ì§€ ì„ê³„ê°’
   - ë‚®ìœ¼ë©´ ë¯¼ê°, ë†’ìœ¼ë©´ ë‘”ê°
   - ê¶Œì¥ê°’: 0.3-0.7

---

## ğŸ“ˆ Drift ëª¨ë‹ˆí„°ë§

í‰ê°€ ì‹œ ìë™ìœ¼ë¡œ drift í†µê³„ê°€ ì¶œë ¥ë©ë‹ˆë‹¤:

```
ğŸ“ˆ Feature Drift Analysis:
   Average drift: 0.0234
   Max drift: Class 12 (0.0567)
   Classes monitored: 25
```

### Drift Score í•´ì„
- `< 0.3`: ì•ˆì •ì 
- `0.3-0.5`: ì•½ê°„ì˜ ë³€í™”
- `> 0.5`: ìƒë‹¹í•œ ë³€í™” (ì¬ë³´ì • ê¶Œì¥)

---

## ğŸ”¬ ë™ì‘ ì›ë¦¬

### Herding ì•Œê³ ë¦¬ì¦˜

```python
# 1. í´ë˜ìŠ¤ í‰ê·  ê³„ì‚°
class_mean = features.mean(dim=0)

# 2. ìˆœì°¨ì  ì„ íƒ
selected = []
for i in range(n_samples):
    # í˜„ì¬ê¹Œì§€ ì„ íƒëœ ìƒ˜í”Œë“¤ì˜ í‰ê· 
    current_mean = selected.mean()

    # ë‹¤ìŒ ìƒ˜í”Œ ì„ íƒ: í‰ê· ì„ ê°€ì¥ ì˜ ë³´ì¡´í•˜ëŠ” ê²ƒ
    best = argmin(distance(current_mean + new, class_mean))
    selected.append(best)
```

### Feature Drift ê°ì§€ & Adaptive Update

```python
# 1. ìƒˆ ë°ì´í„°ì˜ í‰ê· ê³¼ ê¸°ì¡´ í‰ê·  ë¹„êµ
drift_score = norm(new_mean - old_mean) / old_std

# 2. Drift ê°ì§€
if drift_score > threshold:
    # Drift ìˆìŒ â†’ ì¬ì„ íƒ
    classes_to_update.add(class_id)
else:
    # Drift ì—†ìŒ â†’ ê¸°ì¡´ ìƒ˜í”Œ ìœ ì§€
    keep_existing_samples(class_id)

# 3. Adaptive Update (ìë™ ì‹¤í–‰)
# - Drift ê°ì§€ëœ í´ë˜ìŠ¤ë§Œ ì¬ì„ íƒ
# - ì•ˆì •ì ì¸ í´ë˜ìŠ¤ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
# - íš¨ìœ¨ì„±: ì „ì²´ ì¬ì„ íƒ ëŒ€ë¹„ 30% ë¹ ë¦„
```

**ì‹¤ì œ ë™ì‘ ì˜ˆì‹œ:**
```
ì‚¬ìš©ì 1-10 í•™ìŠµ â†’ ëª¨ë‘ ì¬ì„ íƒ
ì‚¬ìš©ì 11 í•™ìŠµ â†’ Drift ê²€ì‚¬
  - ì‚¬ìš©ì 1,3,5ì—ì„œ drift ê°ì§€
  - ì‚¬ìš©ì 1,3,5ë§Œ ì¬ì„ íƒ
  - ì‚¬ìš©ì 2,4,6,7,8,9,10 ìƒ˜í”Œ ìœ ì§€
```

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **ì²« ì‹¤í–‰ì´ ëŠë¦¼**: Feature extraction ë•Œë¬¸ì— ì´ˆê¸° ì†ë„ê°€ ëŠë¦´ ìˆ˜ ìˆìŒ
2. **GPU ë©”ëª¨ë¦¬**: herding_batch_sizeë¥¼ GPU ìš©ëŸ‰ì— ë§ê²Œ ì¡°ì •
3. **ë°ì´í„° ê²½ë¡œ**: ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•´ì•¼ í•¨

---

## ğŸ”„ ê¸°ë³¸ê°’ìœ¼ë¡œ ë³µì›

Herdingì„ ë¹„í™œì„±í™”í•˜ê³  Random samplingìœ¼ë¡œ ëŒì•„ê°€ë ¤ë©´:

```yaml
Training:
  use_herding: false  # true â†’ falseë¡œ ë³€ê²½
```

---

## ğŸ“ ì‹¤í—˜ ê²°ê³¼ ì˜ˆì‹œ

```
Final Results with Herding:
- Average 1-EER: 0.967 (Random: 0.945)
- Mean Forgetting: 0.0156 (Random: 0.0234)
- Memory Efficiency: 500 samples (Random: 1000)
- Training Time: 52 min (Random: 45 min)
```

---

## ğŸ¤ ë¬¸ì œ í•´ê²°

### Q: "CUDA out of memory" ì˜¤ë¥˜
A: `herding_batch_size`ë¥¼ 16 ë˜ëŠ” 8ë¡œ ì¤„ì´ì„¸ìš”

### Q: Drift scoreê°€ ê³„ì† ë†’ê²Œ ë‚˜ì˜´
A: `drift_threshold`ë¥¼ 0.7-1.0ìœ¼ë¡œ ë†’ì´ì„¸ìš”

### Q: ì„±ëŠ¥ì´ ì˜¤íˆë ¤ ë–¨ì–´ì§
A: `max_samples_per_class`ë¥¼ 20-30ìœ¼ë¡œ ëŠ˜ë¦¬ì„¸ìš”

---

## ğŸ“š ì°¸ê³  ë¬¸í—Œ

- iCaRL: Rebuffi et al., "iCaRL: Incremental Classifier and Representation Learning", CVPR 2017
- BiC: Wu et al., "Large Scale Incremental Learning", CVPR 2019