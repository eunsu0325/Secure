# coconut/training/trainer.py
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset, ConcatDataset
from torch.optim import lr_scheduler
import numpy as np
from typing import Dict, List, Tuple, Optional, Set
from tqdm import tqdm
from PIL import Image
import torch.nn.functional as F
import copy
import os
import random

# COCONUT ëª¨ë“ˆ import
from coconut.losses import SupConLoss, ProxyAnchorLoss
from coconut.data import MemoryDataset

# ê¸°ì¡´ ëª¨ë“ˆ import (ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜ˆì •)
from coconut.data import get_scr_transforms
from .average_meter import AverageMeter
from coconut.models import PretrainedLoader
from coconut.classifiers.threshold import ThresholdCalibrator

# ì˜¤í”ˆì…‹ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
try:
    from coconut.openset import (
        split_user_data,
        extract_scores_genuine,
        extract_scores_impostor_between,
        extract_scores_impostor_unknown,
        extract_scores_impostor_negref,
        balance_impostor_scores,
        predict_batch,
        load_paths_labels_from_txt,
        # TTA ê´€ë ¨
        predict_batch_tta,
        extract_scores_genuine_tta,
        extract_scores_impostor_between_tta,
        extract_scores_impostor_negref_tta,
        set_seed
    )
    from coconut.openset.utils import _open_with_channels
    TTA_FUNCTIONS_AVAILABLE = True
except ImportError:
    from coconut.openset import (
        split_user_data,
        extract_scores_genuine,
        extract_scores_impostor_between,
        extract_scores_impostor_unknown,
        extract_scores_impostor_negref,
        balance_impostor_scores,
        predict_batch,
        load_paths_labels_from_txt,
        set_seed
    )
    TTA_FUNCTIONS_AVAILABLE = False
    print("WARNING: TTA functions not available, using max score only")

    def _open_with_channels(path: str, channels: int):
        img = Image.open(path)
        if channels == 1:
            return img.convert('L')
        else:
            return img.convert('RGB')


def worker_init_fn(worker_id):
    """
    Initialize each DataLoader worker with unique seed for reproducibility
    """
    worker_seed = torch.initial_seed() % 2**32
    np.random.seed(worker_seed)
    random.seed(worker_seed)


def repeat_and_augment_data(paths, labels, target_size):
    """ë°ì´í„°ë¥¼ ëª©í‘œ í¬ê¸°ì— ë§ì¶° ë°˜ë³µ ì¦ê°•"""
    if not paths or target_size <= 0:
        return [], []

    if len(paths) >= target_size:
        # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ëœë¤ ìƒ˜í”Œë§
        indices = torch.randperm(len(paths))[:target_size]
        return [paths[i] for i in indices], [labels[i] for i in indices]

    # ë¶€ì¡±í•œ ê²½ìš° ìˆœí™˜ ë°˜ë³µí•´ì„œ ëª©í‘œ í¬ê¸° ë‹¬ì„±
    repeated_paths = []
    repeated_labels = []

    for i in range(target_size):
        idx = i % len(paths)  # ìˆœí™˜ ì¸ë±ìŠ¤
        repeated_paths.append(paths[idx])
        repeated_labels.append(labels[idx])

    return repeated_paths, repeated_labels

# MemoryDataset moved to coconut.data.datasets


class COCONUTTrainer:
    """
    COCONUT Trainer: CCNet + ProxyAnchor + Supervised Contrastive Replay

    Combines:
    - CCNet backbone
    - ProxyAnchorLoss for metric learning
    - Supervised Contrastive Learning (SupCon)
    - Memory replay for continual learning
    - Open-set recognition with TTA support
    """

    def __init__(self,
                 model: nn.Module,
                 ncm_classifier,
                 memory_buffer,
                 config,
                 device='cuda'):

        # ì‹œë“œ ì„¤ì •
        seed = getattr(config.training, 'seed', 42) if hasattr(config, 'training') else 42
        set_seed(seed)
        print(f" Random seed set to {seed}")

        # ëª¨ë¸/NCM ë””ë°”ì´ìŠ¤ ì´ë™
        self.device = device
        model = model.to(device)
        if hasattr(ncm_classifier, 'to'):
            ncm_classifier = ncm_classifier.to(device)

        # ì‚¬ì „í›ˆë ¨ ë¡œë”© (í•œ ë²ˆë§Œ ì‹¤í–‰)
        if hasattr(config.model, 'use_pretrained') and config.model.use_pretrained:
            if config.model.pretrained_path and config.model.pretrained_path.exists():
                print(f"\nğŸ¯ Loading pretrained weights...")
                print(f"   Path: {config.model.pretrained_path}")
                loader = PretrainedLoader()
                try:
                    model = loader.load_ccnet_pretrained(
                        model=model,
                        checkpoint_path=config.model.pretrained_path,
                        device=device,
                        verbose=True
                    )
                    print("âœ… Pretrained weights loaded successfully!")
                except Exception as e:
                    print(f"âš ï¸ WARNING: Failed to load pretrained: {e}")
                    print("   Continuing with current weights...")
            else:
                print(f"âš ï¸ WARNING: Pretrained path not found: {config.model.pretrained_path}")
        else:
            print("ğŸ“¦ Using random initialization (no pretrained weights)")

        self.model = model
        self.ncm = ncm_classifier
        self.memory_buffer = memory_buffer
        self.config = config

        # Loss function
        self.criterion = SupConLoss(
            temperature=config.training.temperature,
            base_temperature=config.training.temperature
        )

        # ProxyAnchorLoss ì´ˆê¸°í™”
        self.use_proxy_anchor = getattr(config.training, 'use_proxy_anchor', True)

        if self.use_proxy_anchor:
            #  ì‹¤ì œ íŠ¹ì§• ì°¨ì›ì— ë§ì¶° ProxyAnchor ì´ˆê¸°í™”
            if config.model.use_projection:
                embedding_dim = config.model.projection_dim  # í”„ë¡œì ì…˜ í—¤ë“œ ì‚¬ìš© ì‹œ
            else:
                embedding_dim = 2048  # getFeatureCode() ì¶œë ¥ ì°¨ì› (fc1 ì¶œë ¥)

            self.proxy_anchor_loss = ProxyAnchorLoss(
                embedding_size=embedding_dim,
                margin=getattr(config.training, 'proxy_margin', 0.1),
                alpha=getattr(config.training, 'proxy_alpha', 32)
            ).to(device)

            print(f"[COCONUT] COCONUT ProxyAnchor initialized with {embedding_dim}D embeddings")

            self.proxy_lambda = getattr(config.training, 'proxy_lambda', 0.3)

            print(f"[COCONUT] ProxyAnchorLoss enabled:")
            print(f"   Margin (Î´): {self.proxy_anchor_loss.margin}")
            print(f"   Alpha (Î±): {self.proxy_anchor_loss.alpha}")
            print(f"   Lambda (fixed): {self.proxy_lambda}")
        else:
            self.proxy_anchor_loss = None
            self.proxy_lambda = 0.0

        # [CORE] í•µì‹¬ ìˆ˜ì •: ì˜µí‹°ë§ˆì´ì € ê´€ë¦¬ ê°œì„ 
        self.base_lr = config.training.learning_rate
        self.proxy_lr_ratio = getattr(config.training, 'proxy_lr_ratio', 10) if self.use_proxy_anchor else 1

        # ì´ˆê¸° ì˜µí‹°ë§ˆì´ì € (ê·¸ë£¹ë³„ í•™ìŠµë¥  ì ìš©)
        self.optimizer = self._create_optimizer_with_grouped_params(include_proxies=False)

        # ìŠ¤ì¼€ì¤„ëŸ¬
        self.scheduler = lr_scheduler.StepLR(
            self.optimizer,
            step_size=config.training.scheduler_step_size,
            gamma=config.training.scheduler_gamma
        )

        # ì˜µí‹°ë§ˆì´ì € ì¬ìƒì„± ì¶”ì 
        self.last_num_proxies = 0

        # Transform
        self.train_transform = get_scr_transforms(
            train=True,
            imside=config.dataset.height,
            channels=config.dataset.channels
        )

        self.test_transform = get_scr_transforms(
            train=False,
            imside=config.dataset.height,
            channels=config.dataset.channels
        )

        # === ì˜¤í”ˆì…‹ ê´€ë ¨ ì´ˆê¸°í™” ===
        self.openset_enabled = hasattr(config, 'openset') and config.openset.enabled

        if self.openset_enabled:
            self.openset_config = config.openset
            self._first_calibration_done = False

            # TTA ì„¤ì • í™•ì¸
            self.use_tta = self.openset_config.tta_n_views > 1
            if self.use_tta:
                if TTA_FUNCTIONS_AVAILABLE:
                    print(f"[TARGET] TTA enabled for evaluation:")
                    print(f"   Views: {self.openset_config.tta_n_views}")
                    print(f"   Include original: {self.openset_config.tta_include_original}")
                    print(f"   Augmentation: {self.openset_config.tta_augmentation_strength}")
                    print(f"   Aggregation: {self.openset_config.tta_aggregation}")

                    # íƒ€ì…ë³„ ë°˜ë³µ ì„¤ì • ì¶œë ¥
                    print(f"   Type-specific repeats:")
                    print(f"     - Genuine: {self.openset_config.tta_n_repeats_genuine}")
                    print(f"     - Between: {self.openset_config.tta_n_repeats_between}")
                else:
                    print("WARNING: TTA requested but functions not available")
                    self.use_tta = False

            # ëª¨ë“œ ë¡œê·¸
            mode_str = f"MAX + TTA({self.openset_config.tta_n_views})" if self.use_tta else "MAX"
            print(f" Open-set mode: {mode_str}")

            # ThresholdCalibrator ì´ˆê¸°í™”
            self.threshold_calibrator = ThresholdCalibrator(
                mode="cosine",
                threshold_mode=config.openset.threshold_mode,
                target_far=config.openset.target_far,
                alpha=config.openset.threshold_alpha,
                max_delta=config.openset.threshold_max_delta,
                clip_range=(-1.0, 1.0),
                min_samples=10,
                verbose=config.openset.verbose_calibration
            )

            # Dev/Train ë°ì´í„° ê´€ë¦¬
            self.dev_data = {}
            self.train_data = {}
            self.registered_users = set()

            # í‰ê°€ íˆìŠ¤í† ë¦¬
            self.evaluation_history = []

            # ì´ˆê¸° ì„ê³„ì¹˜ ì„¤ì •
            initial_tau = config.openset.initial_tau
            if hasattr(self.ncm, 'set_thresholds'):
                self.ncm.set_thresholds(tau_s=initial_tau)
            else:
                self.ncm.tau_s = initial_tau

            # ëª¨ë“œë³„ ì´ˆê¸°ê°’ ì¡°ì •
            if config.openset.threshold_mode == 'far':
                print(f"[TARGET] FAR Target mode enabled")
                print(f"   Target FAR: {config.openset.target_far*100:.1f}%")
            else:
                print(f"[INFO] EER mode enabled")

            print(f"   Initial Ï„_s: {initial_tau}")
        else:
            self.registered_users = set()
            self.use_tta = False
            print(" Open-set mode disabled")

        # Statistics
        self.experience_count = 0

        # BASE_ID ì €ì¥
        self.base_id = int(config.negative.base_id) if hasattr(config, 'negative') else 10000
        print(f"[COCONUT] COCONUTTrainer using BASE_ID: {self.base_id}")

        # ì›Œë°ì—… ê´€ë ¨ íŒŒë¼ë¯¸í„°
        self.warmup_T = int(config.negative.warmup_experiences) if hasattr(config, 'negative') else 4
        self.r0 = float(config.negative.r0) if hasattr(config, 'negative') else 0.5
        self.max_neg_per_class = int(config.negative.max_per_batch) if hasattr(config, 'negative') else 1

        # CuDNN ìµœì í™”
        if torch.backends.cudnn.is_available():
            torch.backends.cudnn.benchmark = True
            torch.backends.cudnn.deterministic = False
            print("[INIT] CuDNN benchmark enabled (speed priority)")

        # ì‚¬ì „í›ˆë ¨ ì‚¬ìš© ì—¬ë¶€ ë¡œê·¸
        if hasattr(config.model, 'use_pretrained') and config.model.use_pretrained:
            print(f"[CORE] COCONUTTrainer initialized with pretrained model")
        else:
            print(f" COCONUTTrainer initialized with random weights")


    def _create_optimizer_with_grouped_params(self, include_proxies=True):
        """ íŒŒë¼ë¯¸í„° ê·¸ë£¹ë³„ë¡œ ë‹¤ë¥¸ í•™ìŠµë¥  ì ìš©í•œ ì˜µí‹°ë§ˆì´ì € ìƒì„±"""
        param_groups = []

        # ë°±ë³¸ê³¼ í”„ë¡œì ì…˜ í—¤ë“œ íŒŒë¼ë¯¸í„° ë¶„ë¦¬
        backbone_params = []
        projection_params = []

        for name, param in self.model.named_parameters():
            if 'projection_head' in name:
                projection_params.append(param)
            else:
                backbone_params.append(param)

        # ë°±ë³¸ íŒŒë¼ë¯¸í„° ê·¸ë£¹ (ì‚¬ì „í•™ìŠµëœ CCNet)
        if backbone_params:
            param_groups.append({
                'params': backbone_params,
                'lr': self.config.training.learning_rate,
                'name': 'backbone'
            })
            print(f"ï¸ Backbone LR: {self.config.training.learning_rate:.6f}")

        # í”„ë¡œì ì…˜ í—¤ë“œ íŒŒë¼ë¯¸í„° ê·¸ë£¹ (ìƒˆë¡œ ì´ˆê¸°í™”ëœ ë ˆì´ì–´)
        if projection_params and self.config.model.use_projection:
            param_groups.append({
                'params': projection_params,
                'lr': self.config.training.projection_learning_rate,
                'name': 'projection'
            })
            print(f" Projection Head LR: {self.config.training.projection_learning_rate:.6f}")

        # í”„ë¡ì‹œ íŒŒë¼ë¯¸í„° ê·¸ë£¹ (ìƒˆë¡œ ì´ˆê¸°í™”ëœ í”„ë¡ì‹œ)
        if include_proxies and self.use_proxy_anchor and hasattr(self, 'proxy_anchor_loss') and self.proxy_anchor_loss.proxies is not None:
            param_groups.append({
                'params': [self.proxy_anchor_loss.proxies],
                'lr': self.base_lr * self.proxy_lr_ratio,
                'name': 'proxies'
            })
            print(f"[COCONUT] Proxies LR: {self.base_lr * self.proxy_lr_ratio:.6f} ({self.proxy_lr_ratio}x)")

        return optim.Adam(param_groups)

    def _recreate_optimizer_with_proxies(self):
        """[CORE] í•µì‹¬ ìˆ˜ì •: í”„ë¡ì‹œ ì¶”ê°€ ì‹œ ì˜µí‹°ë§ˆì´ì € ì•ˆì „ ì¬ìƒì„± (ìƒíƒœ ë³µì› ì œê±°)"""
        if not self.use_proxy_anchor or self.proxy_anchor_loss.proxies is None:
            return

        current_num_proxies = self.proxy_anchor_loss.num_classes

        # í”„ë¡ì‹œ ìˆ˜ê°€ ë³€ê²½ëœ ê²½ìš°ì—ë§Œ ì¬ìƒì„±
        if current_num_proxies != self.last_num_proxies:
            # ìƒˆ ì˜µí‹°ë§ˆì´ì € ìƒì„± (ê·¸ë£¹ë³„ í•™ìŠµë¥  ì ìš©)
            self.optimizer = self._create_optimizer_with_grouped_params(include_proxies=True)

            # ìŠ¤ì¼€ì¤„ëŸ¬ ì¬ìƒì„±
            self.scheduler = lr_scheduler.StepLR(
                self.optimizer,
                step_size=self.config.training.scheduler_step_size,
                gamma=self.config.training.scheduler_gamma
            )

            self.last_num_proxies = current_num_proxies
            print(f" Optimizer recreated with {current_num_proxies} proxies (fresh state)")

    def _dedup_negative_classes(self, paths, labels, max_per_class=1):
        """ë„¤ê±°í‹°ë¸Œ í´ë˜ìŠ¤ ì¤‘ë³µ ì œê±°"""
        out_p, out_l, seen = [], [], set()
        for p, l in zip(paths, labels):
            li = int(l)
            if li >= self.base_id:
                if (li in seen) and (max_per_class == 1):
                    continue
                seen.add(li)
            out_p.append(p)
            out_l.append(l)
        return out_p, out_l

    def _memory_cap_for_ratio(self, num_current, r):
        """r0 ë¹„ìœ¨ ì œí•œ ê³„ì‚°"""
        if r <= 0:
            return 0
        return int((r / max(1e-8, 1.0 - r)) * num_current)

    @torch.no_grad()
    def _extract_features_with_tta(self, batch_images):
        """
        Extract features with Test-Time Augmentation (TTA).

        Args:
            batch_images: Batch of images (B, C, H, W)

        Returns:
            Features tensor (B, D) where D is the feature dimension
        """
        if not hasattr(self, 'openset_config'):
            # No TTA config, fallback to normal extraction using getFeatureCode
            return self.model.getFeatureCode(batch_images)

        # TTA configuration
        n_views = self.openset_config.tta_n_views
        include_original = self.openset_config.tta_include_original
        aug_strength = self.openset_config.tta_augmentation_strength
        aggregation = self.openset_config.tta_aggregation

        # Get augmentation transform
        from torchvision import transforms as T
        from ..openset.tta_operations import get_light_augmentation

        light_aug = get_light_augmentation(aug_strength, self.config.dataset.height)

        batch_size = batch_images.shape[0]
        all_features = []

        self.model.eval()

        for i in range(batch_size):
            img = batch_images[i]  # Single image tensor
            view_features = []

            # Process multiple views
            for v_idx in range(n_views):
                if v_idx == 0 and include_original:
                    # Use original image for first view
                    view = img
                else:
                    # Apply augmentation for other views
                    # Convert tensor to PIL for augmentation
                    img_pil = T.ToPILImage()(img.cpu())
                    aug_img = light_aug(img_pil) if aug_strength > 0 else img_pil
                    view = T.ToTensor()(aug_img).to(img.device)

                # Extract features using getFeatureCode for NCM compatibility (6144D)
                view = view.unsqueeze(0)  # Add batch dimension
                features = self.model.getFeatureCode(view)  # Always use getFeatureCode for NCM

                view_features.append(features.squeeze(0))

            # Aggregate features from multiple views
            view_features = torch.stack(view_features)
            if aggregation == 'mean':
                aggregated = view_features.mean(dim=0)
            elif aggregation == 'median':
                aggregated = view_features.median(dim=0)[0]
            else:
                aggregated = view_features.mean(dim=0)  # Default to mean

            all_features.append(aggregated)

        return torch.stack(all_features)

    def train_experience(self, user_id: int, image_paths: List[str], labels: List[int]) -> Dict:
        """í•˜ë‚˜ì˜ experience (í•œ ëª…ì˜ ì‚¬ìš©ì) í•™ìŠµ - ì˜¤í”ˆì…‹ ì§€ì›."""

        print(f"\n=== Training Experience {self.experience_count}: User {user_id} ===")

        # [CORE] í•µì‹¬ ìˆ˜ì •: í”„ë¡ì‹œ ì¶”ê°€ ë° ì˜µí‹°ë§ˆì´ì € ì¬ìƒì„±
        if self.use_proxy_anchor:
            unique_labels = set(labels)
            real_classes = [l for l in unique_labels if l < self.base_id]

            if real_classes:
                self.proxy_anchor_loss.add_classes(real_classes)
                self._recreate_optimizer_with_proxies()

        # ì›ë³¸ labelsë¥¼ ë³´ì¡´
        original_labels = labels.copy()

        # Step 1: Dev/Train ë¶„ë¦¬ (ì˜¤í”ˆì…‹ ëª¨ë“œì¸ ê²½ìš°)
        if self.openset_enabled:
            train_paths, train_labels, dev_paths, dev_labels = split_user_data(
                image_paths, original_labels,
                dev_ratio=self.openset_config.dev_ratio,
                min_dev=2
            )

            # ì €ì¥
            self.dev_data[user_id] = (dev_paths, dev_labels)
            self.train_data[user_id] = (train_paths, train_labels)

            print(f"[INFO] Data split: Train={len(train_paths)}, Dev={len(dev_paths)}")
        else:
            train_paths = image_paths
            train_labels = original_labels

        self.registered_users.add(user_id)

        #  í˜„ì¬ ì‚¬ìš©ì ë°ì´í„°ë¥¼ experience_batch_sizeë§Œí¼ ì¦ê°•
        augmented_current_paths, augmented_current_labels = repeat_and_augment_data(
            train_paths, train_labels, self.config.training.experience_batch_size
        )

        # ì¦ê°•ëœ í˜„ì¬ ì‚¬ìš©ì ë°ì´í„°ì…‹ ìƒì„±
        current_dataset = MemoryDataset(
            paths=augmented_current_paths,
            labels=augmented_current_labels,
            transform=self.train_transform,
            train=True,
            channels=self.config.dataset.channels
        )

        # í•™ìŠµ í†µê³„
        loss_avg = AverageMeter('Loss')

        # SCR ë…¼ë¬¸ ë°©ì‹: epochë‹¹ ì—¬ëŸ¬ iteration
        self.model.train()

        for epoch in range(self.config.training.epochs_per_experience):
            epoch_loss = 0

            for iteration in range(self.config.training.iterations_per_epoch):

                #  ì¦ê°•ëœ í˜„ì¬ ë°ì´í„°ë¥¼ ì „ì²´ ì‚¬ìš© (ì´ë¯¸ experience_batch_sizeë¡œ ë§ì¶°ì§)
                current_subset = current_dataset

                # ë©”ëª¨ë¦¬ì—ì„œ ìƒ˜í”Œë§
                if len(self.memory_buffer) > 0:
                    memory_paths, memory_labels = self.memory_buffer.sample(
                        self.config.training.memory_batch_size
                    )

                    if torch.is_tensor(memory_labels):
                        memory_labels = memory_labels.cpu().tolist()

                    # ì›Œë°ì—… ê·œì¹™ ì ìš©
                    if self.experience_count < self.warmup_T:
                        memory_paths, memory_labels = self._dedup_negative_classes(
                            memory_paths, memory_labels, max_per_class=self.max_neg_per_class
                        )

                        cap = self._memory_cap_for_ratio(self.config.training.experience_batch_size, self.r0)
                        if cap >= 0 and len(memory_paths) > cap:
                            idx = np.random.choice(len(memory_paths), size=cap, replace=False)
                            memory_paths = [memory_paths[i] for i in idx]
                            memory_labels = [memory_labels[i] for i in idx]
                    else:
                        kept = [(p, l) for p, l in zip(memory_paths, memory_labels) if int(l) < self.base_id]
                        memory_paths, memory_labels = (list(map(list, zip(*kept))) if kept else ([], []))

                    if memory_paths:
                        #  ë©”ëª¨ë¦¬ ë°ì´í„°ë¥¼ memory_batch_sizeë§Œí¼ ì¦ê°•
                        augmented_memory_paths, augmented_memory_labels = repeat_and_augment_data(
                            memory_paths, memory_labels, self.config.training.memory_batch_size
                        )

                        memory_dataset = MemoryDataset(
                            paths=augmented_memory_paths,
                            labels=augmented_memory_labels,
                            transform=self.train_transform,
                            train=True,
                            channels=self.config.dataset.channels
                        )

                        combined_dataset = ConcatDataset([current_subset, memory_dataset])
                    else:
                        combined_dataset = current_subset
                else:
                    combined_dataset = current_subset

                # DataLoaderë¡œ ë°°ì¹˜ ìƒì„±
                batch_loader = DataLoader(
                    combined_dataset,
                    batch_size=len(combined_dataset),
                    shuffle=False,
                    num_workers=0,
                    pin_memory=True,
                    persistent_workers=False
                )

                # í•™ìŠµ
                for data, batch_labels in batch_loader:
                    batch_size = len(batch_labels)

                    view1 = data[0]
                    view2 = data[1]

                    x = torch.cat([view1, view2], dim=0).to(self.device, non_blocking=True)
                    batch_labels = batch_labels.to(self.device, non_blocking=True)

                    self.optimizer.zero_grad()

                    # Forward: CCNetì´ ì•Œì•„ì„œ ì²˜ë¦¬ (projection í¬í•¨)
                    features_all = self.model(x)

                    f1 = features_all[:batch_size]
                    f2 = features_all[batch_size:]

                    # CCNet ê²°ê³¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    features_paired = torch.stack([f1, f2], dim=1)

                    # SupConLoss
                    loss_supcon = self.criterion(features_paired, batch_labels)

                    # ProxyAnchorLoss ì¶”ê°€
                    if self.use_proxy_anchor and self.proxy_anchor_loss.proxies is not None:
                        all_labels = batch_labels.repeat(2)
                        loss_proxy = self.proxy_anchor_loss(features_all, all_labels)

                        # ê³ ì • ê°€ì¤‘ì¹˜ë¡œ ê²°í•©
                        loss = (1 - self.proxy_lambda) * loss_supcon + self.proxy_lambda * loss_proxy

                        if iteration == 0 and epoch == 0:
                            print(f"[COCONUT] Losses - SupCon: {loss_supcon.item():.4f}, ProxyAnchor: {loss_proxy.item():.4f}, Î»: {self.proxy_lambda}")
                    else:
                        loss = loss_supcon

                    loss_avg.update(loss.item(), batch_size)

                    loss.backward()
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                    if self.use_proxy_anchor and self.proxy_anchor_loss.proxies is not None:
                        torch.nn.utils.clip_grad_norm_(self.proxy_anchor_loss.proxies, max_norm=1.0)

                    self.optimizer.step()

                    epoch_loss += loss.item()

            if (epoch + 1) % 1 == 0:
                avg_loss = epoch_loss / self.config.training.iterations_per_epoch
                print(f"  Epoch [{epoch+1}/{self.config.training.epochs_per_experience}] Loss: {avg_loss:.4f}")

                #  ì—í¬í¬ë§ˆë‹¤ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë¶„í¬ ë¶„ì„
                if (epoch + 1) % 5 == 0 or epoch == self.config.training.epochs_per_experience - 1:
                    self._analyze_cosine_distribution_epoch()

        # ë©”ëª¨ë¦¬ ë²„í¼ ì—…ë°ì´íŠ¸
        self.memory_buffer.update_from_dataset(train_paths, train_labels)
        print(f"Memory buffer size after update: {len(self.memory_buffer)}")

        # NCM ì—…ë°ì´íŠ¸
        self._update_ncm()

        # ë””ë²„ê¹…: NCMê³¼ ë²„í¼ ë™ê¸°í™” í™•ì¸
        all_paths, all_labels = self.memory_buffer.get_all_data()
        buffer_classes = set(int(label) for label in all_labels)
        ncm_classes = set(self.ncm.class_means_dict.keys())
        missing = buffer_classes - ncm_classes

        if missing:
            print(f"WARNING:  NCM missing classes: {sorted(list(missing))}")
        else:
            print(f"[OK] NCM synchronized: {len(ncm_classes)} classes")

        # ì£¼ê¸°ì  ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë° í‰ê°€ (ì˜¤í”ˆì…‹ ëª¨ë“œ)
        if self.openset_enabled and len(self.registered_users) % self.config.training.test_interval == 0:

            if len(self.registered_users) >= self.openset_config.warmup_users:
                print("\n" + "="*60)
                print(" THRESHOLD CALIBRATION & EVALUATION")
                print("="*60)

                self._calibrate_threshold()
                metrics = self._evaluate_openset()

                self.evaluation_history.append({
                    'num_users': len(self.registered_users),
                    'tau_s': self.ncm.tau_s,
                    'metrics': metrics
                })

                print("="*60 + "\n")
            else:
                print(f" Warmup phase: {len(self.registered_users)}/{self.openset_config.warmup_users}")

        self.experience_count += 1
        self.scheduler.step()

        return {
            'experience': self.experience_count - 1,
            'user_id': user_id,
            'loss': loss_avg.avg,
            'memory_size': len(self.memory_buffer),
            'num_registered': len(self.registered_users)
        }

    @torch.no_grad()
    def _calibrate_threshold(self):
        """ì„ê³„ì¹˜ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ (íƒ€ì…ë³„ ë…ë¦½ TTA ë°˜ë³µ, ë™ì  ë¹„ìœ¨)"""

        use_tta = self.use_tta and TTA_FUNCTIONS_AVAILABLE

        # íƒ€ì…ë³„ ë…ë¦½ì ì¸ TTA ë°˜ë³µ ì„¤ì •
        n_repeats_genuine = getattr(self.openset_config, 'tta_n_repeats_genuine', 1)
        n_repeats_between = getattr(self.openset_config, 'tta_n_repeats_between', 1)
        n_repeats_negref = 0  # NegRef not used

        repeat_agg = getattr(self.openset_config, 'tta_repeat_aggregation', 'median')
        tta_verbose = getattr(self.openset_config, 'tta_verbose', False)

        seed = getattr(self.config.training, 'seed', 42)
        img_size = self.config.dataset.height
        channels = self.config.dataset.channels

        # ëª¨ë“œ í‘œì‹œ
        mode_str = f"MAX + TTA(views={self.openset_config.tta_n_views})" if use_tta else "MAX"
        print(f" Using {mode_str} scores for calibration")

        # íƒ€ì…ë³„ ë°˜ë³µ ì„¤ì • ì¶œë ¥
        if use_tta:
            print(f" TTA with type-specific repeats:")
            print(f"   Genuine: {self.openset_config.tta_n_views} views Ã— {n_repeats_genuine} repeats")
            print(f"   Between: {self.openset_config.tta_n_views} views Ã— {n_repeats_between} repeats")
            print(f"   NegRef: {self.openset_config.tta_n_views} views Ã— {n_repeats_negref} repeats")

        print(f"\n Extracting scores for {self.openset_config.threshold_mode.upper()} calibration...")

        # Dev ë°ì´í„° ìˆ˜ì§‘
        all_dev_paths = []
        all_dev_labels = []
        for uid, (paths, labels) in self.dev_data.items():
            all_dev_paths.extend(paths)
            all_dev_labels.extend([uid] * len(paths))

        # TTA ëª¨ë“œì— ë”°ë¥¸ ì ìˆ˜ ì¶”ì¶œ
        if use_tta:
            s_genuine = extract_scores_genuine_tta(
                self.model, self.ncm,
                all_dev_paths, all_dev_labels,
                self.test_transform, self.device,
                n_views=self.openset_config.tta_n_views,
                include_original=self.openset_config.tta_include_original,
                aug_strength=self.openset_config.tta_augmentation_strength,
                aggregation=self.openset_config.tta_aggregation,
                img_size=img_size,
                channels=channels,
                n_repeats=n_repeats_genuine,
                repeat_aggregation=repeat_agg,
                verbose=tta_verbose,
                seed=seed
            )

            s_imp_between = extract_scores_impostor_between_tta(
                self.model, self.ncm,
                all_dev_paths, all_dev_labels,
                self.test_transform, self.device,
                n_views=self.openset_config.tta_n_views,
                include_original=self.openset_config.tta_include_original,
                aug_strength=self.openset_config.tta_augmentation_strength,
                aggregation=self.openset_config.tta_aggregation,
                max_pairs=6000,
                img_size=img_size,
                channels=channels,
                n_repeats=n_repeats_between,
                repeat_aggregation=repeat_agg,
                verbose=tta_verbose,
                seed=seed
            )

            s_imp_negref = extract_scores_impostor_negref_tta(
                self.model, self.ncm,
                self.config.dataset.negative_samples_file,
                self.test_transform, self.device,
                n_views=self.openset_config.tta_n_views,
                include_original=self.openset_config.tta_include_original,
                aug_strength=self.openset_config.tta_augmentation_strength,
                aggregation=self.openset_config.tta_aggregation,
                img_size=img_size,
                channels=channels,
                n_repeats=n_repeats_negref,
                repeat_aggregation=repeat_agg,
                verbose=tta_verbose,
                seed=seed,
                force_memory_save=False
            )
        else:
            # ë‹¨ì¼ë·° - ìµœëŒ“ê°’ ë²„ì „
            s_genuine = extract_scores_genuine(
                self.model, self.ncm,
                all_dev_paths, all_dev_labels,
                self.test_transform, self.device,
                channels=channels
            )

            s_imp_between = extract_scores_impostor_between(
                self.model, self.ncm,
                all_dev_paths, all_dev_labels,
                self.test_transform, self.device,
                max_pairs=2000,
                channels=channels
            )

            s_imp_negref = extract_scores_impostor_negref(
                self.model, self.ncm,
                self.config.dataset.negative_samples_file,
                self.test_transform, self.device,
                channels=channels
            )

        # ë™ì  ë¹„ìœ¨ë¡œ ê· í˜• ë§ì¶”ê¸°
        # Use only between impostor scores (100%)
        impostor_ratio = (
            1.0,  # Between: 100%
            0.0,  # Unknown: 0%
            0.0   # NegRef: 0%
        )

        s_impostor = balance_impostor_scores(
            s_imp_between,
            None,  # Unknown not used
            None,  # NegRef not used
            ratio=impostor_ratio,
            total=self.openset_config.impostor_balance_total
        )

        print(f"   Genuine: {len(s_genuine)} scores")
        print(f"   Impostor: {len(s_impostor)} scores (100% between)")

        # ìº˜ë¦¬ë¸Œë ˆì´ì…˜
        if len(s_genuine) >= 10 and len(s_impostor) >= 10:
            result = self.threshold_calibrator.calibrate(
                genuine_scores=s_genuine,
                impostor_scores=s_impostor,
                old_tau=None if not self._first_calibration_done else self.ncm.tau_s
            )
            self._first_calibration_done = True

            # NCMì— ì ìš©
            new_tau = result['tau_smoothed']
            if hasattr(self.ncm, 'set_thresholds'):
                self.ncm.set_thresholds(tau_s=new_tau)
            else:
                self.ncm.tau_s = new_tau

            # ëª¨ë“œë³„ ì¶œë ¥
            if self.openset_config.threshold_mode == 'eer':
                print(f" EER Mode Results:")
                print(f"   EER: {result.get('eer', 0)*100:.2f}%")
                print(f"   Threshold: {result['tau_smoothed']:.4f}")
            else:
                print(f"[TARGET] FAR Target Results:")
                print(f"   Target FAR: {self.openset_config.target_far*100:.1f}%")
                print(f"   Achieved FAR: {result.get('current_far', 0)*100:.1f}%")
                print(f"   Threshold: {result['tau_smoothed']:.4f}")
        else:
            print("WARNING: Not enough samples for calibration")

    @torch.no_grad()
    def _evaluate_openset(self):
        """ì˜¤í”ˆì…‹ í‰ê°€ (TTA ì§€ì›)"""

        #  ì¬í˜„ì„±: í‰ê°€ ì‹œ ì‹œë“œ ì¬ì„¤ì •
        eval_seed = getattr(self.config.training, 'seed', 42)
        set_seed(eval_seed)

        use_tta = self.use_tta and TTA_FUNCTIONS_AVAILABLE
        img_size = self.config.dataset.height
        channels = self.config.dataset.channels

        if use_tta:
            print(f"\n Open-set Evaluation with TTA (n={self.openset_config.tta_n_views}):")
        else:
            print("\n Open-set Evaluation (Single View):")

        # ë³€ìˆ˜ ì´ˆê¸°í™”
        TAR = FRR = 0.0
        TRR_u = FAR_u = 0.0
        TRR_n = FAR_n = None

        # 1. Known-Dev (TAR/FRR)
        all_dev_paths = []
        all_dev_labels = []
        for uid, (paths, labels) in self.dev_data.items():
            all_dev_paths.extend(paths)
            all_dev_labels.extend([uid] * len(paths))

        if all_dev_paths:
            if use_tta:
                preds, details = predict_batch_tta(
                    self.model, self.ncm,
                    all_dev_paths, self.test_transform, self.device,
                    n_views=self.openset_config.tta_n_views,
                    include_original=self.openset_config.tta_include_original,
                    agree_k=self.openset_config.tta_agree_k,
                    aug_strength=self.openset_config.tta_augmentation_strength,
                    return_details=True,
                    img_size=img_size,
                    channels=channels,
                    seed=eval_seed + 5000  #  ì¬í˜„ì„±: seed ì „ë‹¬
                )

                # TTA í†µê³„ ì¶œë ¥
                if details:
                    reject_reasons = [d.get('reject_reason') for d in details if d.get('reject_reason')]
                    if reject_reasons:
                        from collections import Counter
                        reason_counts = Counter(reject_reasons)
                        print(f"   TTA Reject reasons: gate={reason_counts.get('gate', 0)}, "
                              f"class={reason_counts.get('class', 0)}, both={reason_counts.get('both', 0)}")
            else:
                preds = predict_batch(
                    self.model, self.ncm,
                    all_dev_paths, self.test_transform, self.device,
                    channels=channels
                )

            # TAR/FRR ê³„ì‚°
            correct = sum(1 for p, l in zip(preds, all_dev_labels) if p == l)
            rejected = sum(1 for p in preds if p == -1)

            TAR = correct / max(1, len(preds))
            FRR = rejected / max(1, len(preds))

        # 2. Unknown (TRR/FAR)
        unknown_paths, unknown_labels = load_paths_labels_from_txt(
            str(self.config.dataset.train_set_file)
        )

        unknown_filtered = []
        for p, l in zip(unknown_paths, unknown_labels):
            if l not in self.registered_users:
                unknown_filtered.append(p)

        if len(unknown_filtered) > 1000:
            #  ì¬í˜„ì„±: config seed ê¸°ë°˜ ìƒ˜í”Œë§
            np.random.seed(eval_seed + 1000)  # deterministic offset
            unknown_filtered = np.random.choice(unknown_filtered, 1000, replace=False).tolist()

        if unknown_filtered:
            if use_tta:
                preds_unk = predict_batch_tta(
                    self.model, self.ncm,
                    unknown_filtered, self.test_transform, self.device,
                    n_views=self.openset_config.tta_n_views,
                    include_original=self.openset_config.tta_include_original,
                    agree_k=self.openset_config.tta_agree_k,
                    aug_strength=self.openset_config.tta_augmentation_strength,
                    img_size=img_size,
                    channels=channels,
                    seed=eval_seed + 3000  #  ì¬í˜„ì„±: seed ì „ë‹¬
                )
            else:
                preds_unk = predict_batch(
                    self.model, self.ncm,
                    unknown_filtered, self.test_transform, self.device,
                    channels=channels
                )
            TRR_u = sum(1 for p in preds_unk if p == -1) / len(preds_unk)
            FAR_u = 1 - TRR_u

        # 3. NegRef
        negref_paths, _ = load_paths_labels_from_txt(
            str(self.config.dataset.negative_samples_file)
        )

        if len(negref_paths) > 1000:
            #  ì¬í˜„ì„±: config seed ê¸°ë°˜ ìƒ˜í”Œë§
            np.random.seed(eval_seed + 2000)  # deterministic offset
            negref_paths = np.random.choice(negref_paths, 1000, replace=False).tolist()

        if negref_paths:
            if use_tta:
                preds_neg = predict_batch_tta(
                    self.model, self.ncm,
                    negref_paths, self.test_transform, self.device,
                    n_views=self.openset_config.tta_n_views,
                    include_original=self.openset_config.tta_include_original,
                    agree_k=self.openset_config.tta_agree_k,
                    aug_strength=self.openset_config.tta_augmentation_strength,
                    img_size=img_size,
                    channels=channels,
                    seed=eval_seed + 4000  #  ì¬í˜„ì„±: seed ì „ë‹¬
                )
            else:
                preds_neg = predict_batch(
                    self.model, self.ncm,
                    negref_paths, self.test_transform, self.device,
                    channels=channels
                )
            TRR_n = sum(1 for p in preds_neg if p == -1) / len(preds_neg)
            FAR_n = 1 - TRR_n

        # ê²°ê³¼ ì¶œë ¥
        print(f"   Known-Dev: TAR={TAR:.3f}, FRR={FRR:.3f}")
        print(f"   Unknown: TRR={TRR_u:.3f}, FAR={FAR_u:.3f}")
        if TRR_n is not None:
            print(f"   NegRef: TRR={TRR_n:.3f}, FAR={FAR_n:.3f}")
        print(f"   Threshold: Ï„_s={self.ncm.tau_s:.4f}")

        # ëª¨ë“œ ì •ë³´ ì¶”ê°€
        if self.openset_config.threshold_mode == 'far':
            print(f"   Mode: FAR Target ({self.openset_config.target_far*100:.1f}%)")
        else:
            print(f"   Mode: EER")

        print(f"   Score: Max")

        if use_tta:
            print(f"   [TARGET] TTA: {self.openset_config.tta_n_views} views, agree_k={self.openset_config.tta_agree_k}")

        return {
            'TAR': TAR, 'FRR': FRR,
            'TRR_unknown': TRR_u, 'FAR_unknown': FAR_u,
            'TRR_negref': TRR_n, 'FAR_negref': FAR_n,
            'mode': self.openset_config.threshold_mode,
            'score_type': 'max',
            'tta_enabled': use_tta,
            'tta_views': self.openset_config.tta_n_views if use_tta else 1
        }

    @torch.no_grad()
    def _update_ncm(self):
        """NCM classifierì˜ class meansë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        if len(self.memory_buffer) == 0:
            return

        self.model.eval()

        # ë©”ëª¨ë¦¬ ë²„í¼ì—ì„œ ëª¨ë“  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        all_paths, all_labels = self.memory_buffer.get_all_data()

        # ê°€ì§œ í´ë˜ìŠ¤ í•„í„°ë§
        real_paths = []
        real_labels = []
        fake_count = 0

        for path, label in zip(all_paths, all_labels):
            label_int = int(label) if not isinstance(label, int) else label
            if label_int < self.base_id:
                real_paths.append(path)
                real_labels.append(label)
            else:
                fake_count += 1

        if not real_paths:
            print("WARNING: No real users for NCM update (NCM remains empty)")
            return

        if fake_count > 0:
            print(f" NCM update: {len(real_paths)} real samples ({fake_count} fake samples filtered out)")

        # ë°ì´í„°ì…‹ ìƒì„±
        dataset = MemoryDataset(
            paths=real_paths,
            labels=real_labels,
            transform=self.test_transform,
            train=False,
            channels=self.config.dataset.channels
        )

        dataloader = DataLoader(
            dataset,
            batch_size=128,
            shuffle=False,
            num_workers=self.config.training.num_workers,
            worker_init_fn=worker_init_fn if self.config.training.num_workers > 0 else None,
            pin_memory=True,
            persistent_workers=False
        )

        # í´ë˜ìŠ¤ë³„ë¡œ features ìˆ˜ì§‘
        class_features = {}

        for data, labels in dataloader:
            data = data.to(self.device, non_blocking=True)
            labels = labels.to(self.device, non_blocking=True)

            features = self.model.getFeatureCode(data)

            for i, label in enumerate(labels):
                label_item = label.item()
                if label_item not in class_features:
                    class_features[label_item] = []
                class_features[label_item].append(features[i].cpu())

        # í´ë˜ìŠ¤ë³„ í‰ê·  ê³„ì‚°
        class_means = {}
        for label, features_list in class_features.items():
            if len(features_list) > 0:
                mean_feature = torch.stack(features_list).mean(dim=0)
                mean_feature = mean_feature / (mean_feature.norm(p=2) + 1e-12)
                class_means[label] = mean_feature

        # NCM ì—…ë°ì´íŠ¸
        self.ncm.replace_class_means_dict(class_means)

        real_classes = [k for k in class_means.keys() if k < self.base_id]
        print(f" Updated NCM with {len(real_classes)} real classes (no fake contamination)")

        self.model.train()

    @torch.no_grad()
    def _analyze_cosine_distribution_epoch(self):
        """ ì—í¬í¬ë§ˆë‹¤ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë¶„í¬ ë¶„ì„"""
        if len(self.memory_buffer) < 20:  # ìµœì†Œ ìƒ˜í”Œ ìˆ˜ í™•ì¸
            return

        # í˜„ì¬ ëª¨ë¸ ëª¨ë“œ ì €ì¥
        was_training = self.model.training
        self.model.eval()

        # ë©”ëª¨ë¦¬ ë²„í¼ì—ì„œ ëª¨ë“  ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ì‹¤ì œ ì‚¬ìš©ìë§Œ)
        all_paths, all_labels = self.memory_buffer.get_all_data()

        # ê°€ì§œ í´ë˜ìŠ¤ í•„í„°ë§
        real_paths = []
        real_labels = []
        for path, label in zip(all_paths, all_labels):
            label_int = int(label) if not isinstance(label, int) else label
            if label_int < self.base_id:
                real_paths.append(path)
                real_labels.append(label_int)

        if len(real_paths) < 10:
            # ëª¨ë“œ ë³µì› í›„ ë¦¬í„´
            if was_training:
                self.model.train()
            return

        # ìƒ˜í”Œë§ (ë„ˆë¬´ ë§ìœ¼ë©´ ì¼ë¶€ë§Œ)
        if len(real_paths) > 200:
            indices = np.random.choice(len(real_paths), 200, replace=False)
            real_paths = [real_paths[i] for i in indices]
            real_labels = [real_labels[i] for i in indices]

        # [TARGET] ê¸°ì¡´ ë°©ì‹ê³¼ ë™ì¼í•œ NCM ê¸°ë°˜ ìŠ¤ì½”ì–´ ê³„ì‚°
        genuine_scores = []
        impostor_scores = []

        # í´ë˜ìŠ¤ë³„ë¡œ ë°ì´í„° ë¶„ë¥˜
        from collections import defaultdict
        by_class = defaultdict(list)
        for path, label in zip(real_paths, real_labels):
            by_class[int(label)].append(path)

        # Genuine ìŠ¤ì½”ì–´ ê³„ì‚° (ê°™ì€ í´ë˜ìŠ¤ ë‚´)
        for cls_id, cls_paths in by_class.items():
            if len(cls_paths) < 2:
                continue

            # í´ë˜ìŠ¤ ë‚´ì—ì„œ ìƒ˜í”Œë§
            sample_paths = cls_paths[:min(5, len(cls_paths))]

            for path in sample_paths:
                # íŠ¹ì§• ì¶”ì¶œ
                img = _open_with_channels(path, self.config.dataset.channels)
                img_tensor = self.test_transform(img).unsqueeze(0).to(self.device)

                # NCM ì ìˆ˜ ê³„ì‚° (6144D íŠ¹ì§• ì‚¬ìš©)
                feat = self.model.getFeatureCode(img_tensor)
                ncm_scores = self.ncm.forward(feat)

                if ncm_scores.numel() > 0:
                    #  ìˆ˜ì •: í´ë˜ìŠ¤ IDë¥¼ ì§ì ‘ ì¸ë±ìŠ¤ë¡œ ì‚¬ìš©
                    if cls_id in self.ncm.class_means_dict and cls_id < ncm_scores.shape[1]:
                        genuine_score = ncm_scores[0, cls_id].item()
                        genuine_scores.append(genuine_score)

        # Impostor ìŠ¤ì½”ì–´ ê³„ì‚° (ë‹¤ë¥¸ í´ë˜ìŠ¤ë“¤)
        max_impostor_samples = 50
        impostor_count = 0

        for cls_id, cls_paths in by_class.items():
            if impostor_count >= max_impostor_samples:
                break

            # í´ë˜ìŠ¤ë‹¹ ìµœëŒ€ 3ê°œ ìƒ˜í”Œ
            sample_paths = cls_paths[:min(3, len(cls_paths))]

            for path in sample_paths:
                if impostor_count >= max_impostor_samples:
                    break

                # íŠ¹ì§• ì¶”ì¶œ
                img = _open_with_channels(path, self.config.dataset.channels)
                img_tensor = self.test_transform(img).unsqueeze(0).to(self.device)

                # NCM ì ìˆ˜ ê³„ì‚°
                feat = self.model.getFeatureCode(img_tensor)
                ncm_scores = self.ncm.forward(feat)

                if ncm_scores.numel() > 0:
                    # ìœ íš¨í•œ í´ë˜ìŠ¤ë§Œìœ¼ë¡œ Impostor ì ìˆ˜ ê³„ì‚°
                    valid_ids = sorted(self.ncm.class_means_dict.keys())
                    if len(valid_ids) > 1:  # ìµœì†Œ 2ê°œ í´ë˜ìŠ¤ í•„ìš”
                        scores_valid = ncm_scores[:, valid_ids].clone()
                        own_col = valid_ids.index(cls_id) if cls_id in valid_ids else None
                        if own_col is not None:
                            scores_valid[0, own_col] = -1e9

                        max_score = scores_valid.max(dim=1).values.item()
                        if max_score > -1e9:
                            impostor_scores.append(max_score)
                            impostor_count += 1

        #  ë””ë²„ê¹…: NCMê³¼ ë©”ëª¨ë¦¬ ë²„í¼ ë™ê¸°í™” í™•ì¸
        print(f"\n NCM Classes: {sorted(list(self.ncm.class_means_dict.keys()))}")
        print(f" Memory Classes: {sorted(list(set(real_labels)))}")
        print(f" Sample count - Genuine: {len(genuine_scores)}, Impostor: {len(impostor_scores)}")

        # í†µê³„ ê³„ì‚° ë° ì¶œë ¥
        if genuine_scores and impostor_scores:
            genuine_mean = np.mean(genuine_scores)
            genuine_std = np.std(genuine_scores)
            impostor_mean = np.mean(impostor_scores)
            impostor_std = np.std(impostor_scores)
            separation = genuine_mean - impostor_mean

            print(f"     NCM Score Distribution (like EER Calculation):")
            print(f"       Genuine:  {genuine_mean:.3f} Â± {genuine_std:.3f} (n={len(genuine_scores)})")
            print(f"       Impostor: {impostor_mean:.3f} Â± {impostor_std:.3f} (n={len(impostor_scores)})")
            print(f"       Separation: {separation:.3f}")

            # NCM ìŠ¤ì½”ì–´ ê¸°ì¤€ ì„±ëŠ¥ í‰ê°€ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ì™€ ë‹¤ë¥¸ ê¸°ì¤€)
            if separation > 0.3:
                print(f"       Status:  Excellent separation")
            elif separation > 0.2:
                print(f"       Status:  Good separation")
            elif separation > 0.1:
                print(f"       Status:  Moderate separation")
            else:
                print(f"       Status:  Poor separation")

        # ì›ë˜ ëª¨ë¸ ëª¨ë“œ ë³µì›
        if was_training:
            self.model.train()
        else:
            self.model.eval()

    def evaluate(self, test_dataset: Dataset) -> float:
        """NCMì„ ì‚¬ìš©í•˜ì—¬ ì •í™•ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤."""
        self.model.eval()

        dataloader = DataLoader(
            test_dataset,
            batch_size=128,
            shuffle=False,
            num_workers=self.config.training.num_workers,
            worker_init_fn=worker_init_fn if self.config.training.num_workers > 0 else None,
            pin_memory=True,
            persistent_workers=False
        )

        correct = 0
        total = 0

        with torch.no_grad():
            for data, labels in dataloader:
                data = data.to(self.device, non_blocking=True)
                labels = labels.to(self.device, non_blocking=True)

                features = self.model.getFeatureCode(data)
                predictions = self.ncm.predict(features)

                correct += (predictions == labels).sum().item()
                total += labels.size(0)

        accuracy = 100.0 * correct / total
        return accuracy

    def save_checkpoint(self, path: str):
        """[CORE] ì•ˆì „í•œ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (ë””ë ‰í† ë¦¬ ìƒì„± ì¶”ê°€)"""
        # ë””ë ‰í† ë¦¬ ìƒì„±
        save_dir = os.path.dirname(path)
        if save_dir:
            os.makedirs(save_dir, exist_ok=True)

        checkpoint_dict = {
            'model_state_dict': self.model.state_dict(),
            'ncm_state_dict': self.ncm.state_dict(),
            'experience_count': self.experience_count,
            'memory_buffer_size': len(self.memory_buffer)
        }

        # ì˜µí‹°ë§ˆì´ì € ìƒíƒœ ì•ˆì „ ì €ì¥
        try:
            checkpoint_dict['optimizer_state_dict'] = self.optimizer.state_dict()
            checkpoint_dict['scheduler_state_dict'] = self.scheduler.state_dict()
        except Exception as e:
            print(f"Warning: Could not save optimizer/scheduler state: {e}")

        # ProxyAnchorLoss ê´€ë ¨ ì €ì¥
        if self.use_proxy_anchor and self.proxy_anchor_loss.proxies is not None:
            try:
                checkpoint_dict['proxy_anchor_data'] = {
                    'proxies': self.proxy_anchor_loss.proxies.detach().cpu(),
                    'class_to_idx': self.proxy_anchor_loss.class_to_idx.copy(),
                    'num_classes': self.proxy_anchor_loss.num_classes
                }
            except Exception as e:
                print(f"Warning: Could not save proxy anchor data: {e}")

        # ì˜¤í”ˆì…‹ ê´€ë ¨ ì¶”ê°€ ì €ì¥
        if self.openset_enabled:
            try:
                checkpoint_dict['openset_data'] = {
                    'tau_s': self.ncm.tau_s,
                    'registered_users': list(self.registered_users),
                    'evaluation_history': self.evaluation_history
                }
            except Exception as e:
                print(f"Warning: Could not save openset data: {e}")

        torch.save(checkpoint_dict, path)
        print(f"[OK] Checkpoint saved to: {path}")
