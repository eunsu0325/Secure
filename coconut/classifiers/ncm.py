"""
NCM (Nearest Class Mean) Classifier for COCONUT
ìµœì í™”ëœ ê±°ë¦¬ ê¸°ë°˜ ë¶„ë¥˜ê¸°
"""

from typing import Dict
import torch
from torch import Tensor, nn
import torch.nn.functional as F


class NCMClassifier(nn.Module):
    """
    NCM (Nearest Class Mean) Classifier - ìµœì í™” ë²„ì „.

    ðŸš€ ìµœì í™”: cdist ëŒ€ì‹  í–‰ë ¬ê³± ì‚¬ìš© (2-3ë°° ë¹ ë¦„)
    âœ… normalize=True: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜
    """

    def __init__(self, normalize: bool = True):
        super().__init__()
        self.register_buffer("class_means", None)
        self.class_means_dict = {}
        self.normalize = normalize
        self.max_class = -1

        # ì˜¤í”ˆì…‹ ê´€ë ¨
        self.tau_s = None            # ì „ì—­ ìž„ê³„ì¹˜
        self.unknown_id = -1         # Unknown í´ëž˜ìŠ¤ ID

    def load_state_dict(self, state_dict, strict: bool = True):
        """ì²´í¬í¬ì¸íŠ¸ì—ì„œ ìƒíƒœë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        self.class_means = state_dict["class_means"]
        super().load_state_dict(state_dict, strict)
        if self.class_means is not None:
            for i in range(self.class_means.shape[0]):
                if (self.class_means[i] != 0).any():
                    self.class_means_dict[i] = self.class_means[i].clone()
        self.max_class = max(self.class_means_dict.keys()) if self.class_means_dict else -1

    def _vectorize_means_dict(self):
        """ë”•ì…”ë„ˆë¦¬ë¥¼ í…ì„œë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        if self.class_means_dict == {}:
            return

        max_class = max(self.class_means_dict.keys())
        self.max_class = max(max_class, self.max_class)

        first_mean = list(self.class_means_dict.values())[0]
        feature_size = first_mean.size(0)
        device = first_mean.device

        self.class_means = torch.zeros(self.max_class + 1, feature_size).to(device)

        for k, v in self.class_means_dict.items():
            self.class_means[k] = self.class_means_dict[k].clone()

    @torch.no_grad()
    def forward(self, x):
        """
        ðŸš€ ìµœì í™”ëœ NCM ë¶„ë¥˜

        normalize=True: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (ì •ê·œí™” í›„ ë‚´ì )
        normalize=False: ìœ í´ë¦¬ë””ì•ˆ ê±°ë¦¬ (ì œê³± ê±°ë¦¬ ì‚¬ìš©)
        """
        # NCMì´ ë¹„ì–´ìžˆìœ¼ë©´ ë¹ˆ ì ìˆ˜ ë°˜í™˜
        if self.class_means_dict == {}:
            return torch.zeros((x.shape[0], 0), device=x.device, dtype=x.dtype)

        # dtype ì¼ì¹˜ ë³´ìž¥ (fp16/AMP ì§€ì›)
        M = self.class_means.to(device=x.device, dtype=x.dtype)

        if self.normalize:
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜
            x = F.normalize(x, p=2, dim=1, eps=1e-12)
            scores = x @ M.T  # (B, C)
            return scores  # ë†’ì„ìˆ˜ë¡ ê°€ê¹Œì›€
        else:
            # ìœ í´ë¦¬ë””ì•ˆ ê±°ë¦¬ ê¸°ë°˜
            x2 = (x * x).sum(dim=1, keepdim=True)      # (B, 1)
            m2 = (M * M).sum(dim=1, keepdim=False)      # (C,)
            xm = x @ M.T                                # (B, C)
            scores = -(x2 + m2.unsqueeze(0) - 2 * xm)  # (B, C)
            return scores  # ë†’ì„ìˆ˜ë¡ ê°€ê¹Œì›€ (negative distance)

    def replace_class_means_dict(self, class_means_dict: Dict[int, Tensor]):
        """
        ê¸°ì¡´ í‰ê· ì„ ì™„ì „ížˆ êµì²´í•©ë‹ˆë‹¤.
        í˜„ìž¬ ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ” ë©”ì„œë“œ
        """
        assert isinstance(class_means_dict, dict)

        self.class_means_dict = {k: v.clone() for k, v in class_means_dict.items()}

        # ë°©ì–´ì  ì •ê·œí™” (normalize=Trueì¼ ë•Œ)
        if self.normalize:
            for k in self.class_means_dict:
                self.class_means_dict[k] = F.normalize(
                    self.class_means_dict[k], p=2, dim=0, eps=1e-12
                )

        self._vectorize_means_dict()

    def predict(self, x):
        """í´ëž˜ìŠ¤ ì˜ˆì¸¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        # NCMì´ ë¹„ì–´ìžˆìœ¼ë©´ -1 ë°˜í™˜
        if len(self.class_means_dict) == 0:
            return torch.full((x.shape[0],), -1, dtype=torch.long, device=x.device)

        scores = self.forward(x)
        return scores.argmax(dim=1)

    def get_num_classes(self):
        """í˜„ìž¬ ì €ìž¥ëœ í´ëž˜ìŠ¤ ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return len(self.class_means_dict)

    def get_class_means(self):
        """í˜„ìž¬ ì €ìž¥ëœ í´ëž˜ìŠ¤ í‰ê· ë“¤ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return self.class_means_dict.copy()

    def set_thresholds(self, tau_s: float):
        """ì˜¤í”ˆì…‹ ìž„ê³„ì¹˜ ì„¤ì •"""
        self.tau_s = float(tau_s)

    @torch.no_grad()
    def predict_openset(self, x):
        """ì˜¤í”ˆì…‹ ì˜ˆì¸¡ (ìµœëŒ“ê°’ ëª¨ë“œ)"""
        # NCMì´ ë¹„ì–´ìžˆìœ¼ë©´ ëª¨ë‘ -1 ë°˜í™˜
        if len(self.class_means_dict) == 0:
            return torch.full((x.shape[0],), -1, dtype=torch.long, device=x.device)

        # ê¸°ì¡´ ìµœëŒ“ê°’ ëª¨ë“œ
        scores = self.forward(x)  # (B, C)

        # Top-1 ì¶”ì¶œ
        top1 = scores.topk(1, dim=1)
        max_score = top1.values[:, 0]
        pred = top1.indices[:, 0]

        # ìž„ê³„ì¹˜ ì ìš©
        if self.tau_s is not None:
            accept = max_score >= self.tau_s
        else:
            accept = torch.ones_like(max_score, dtype=torch.bool)

        pred[~accept] = self.unknown_id

        return pred
