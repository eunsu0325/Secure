# ğŸŒ• Avalancheì˜ storage_policy.pyì—ì„œ í•„ìš”í•œ ë¶€ë¶„ë§Œ ê°€ì ¸ì˜´
#memory_buffer.py

from collections import defaultdict, deque  # ğŸ’ deque ì¶”ê°€
import random
from typing import Dict, List, Set, Optional, Tuple
import torch
import numpy as np  # ğŸ’ ì¶”ê°€

class ReservoirSamplingBuffer:  # ğŸŒ• Avalanche storage_policy.py ë¼ì¸ 88-128 ê·¸ëŒ€ë¡œ
    """
    Buffer updated with reservoir sampling.
    
    Reservoir Samplingì€ ì „ì²´ ë°ì´í„° í¬ê¸°ë¥¼ ëª¨ë¥´ëŠ” ìƒí™©ì—ì„œë„
    ëª¨ë“  ìƒ˜í”Œì´ ë™ì¼í•œ í™•ë¥ ë¡œ ì„ íƒë˜ë„ë¡ ë³´ì¥í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.
    """

    def __init__(self, max_size: int):
        """
        :param max_size: ë²„í¼ì— ì €ì¥í•  ìˆ˜ ìˆëŠ” ìµœëŒ€ ìƒ˜í”Œ ìˆ˜
        """
        # Reservoir Sampling ì•Œê³ ë¦¬ì¦˜:
        # 1. ê° ìƒ˜í”Œì— [0,1] ë²”ìœ„ì˜ random weight í• ë‹¹
        # 2. weightê°€ ë†’ì€ ìˆœì„œëŒ€ë¡œ max_sizeê°œ ì„ íƒ
        # 3. ì´ëŠ” uniform random samplingê³¼ ìˆ˜í•™ì ìœ¼ë¡œ ë™ì¼
        super().__init__()
        self.max_size = max_size
        # _buffer_weightsëŠ” í•­ìƒ ì •ë ¬ëœ ìƒíƒœ ìœ ì§€ (ë‚´ë¦¼ì°¨ìˆœ)
        self._buffer_weights = torch.zeros(0)
        self.buffer = []  # ğŸ£ (data, label) íŠœí”Œ ë¦¬ìŠ¤íŠ¸

    def update_from_dataset(self, new_data: List, new_labels: List):  # ğŸ£ ìˆ˜ì •: List ì…ë ¥
        """
        ìƒˆë¡œìš´ ë°ì´í„°ë¡œ ë²„í¼ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        
        :param new_data: ìƒˆë¡œìš´ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (ì´ë¯¸ì§€ ê²½ë¡œ ë˜ëŠ” í…ì„œ)
        :param new_labels: ìƒˆë¡œìš´ ë ˆì´ë¸” ë¦¬ìŠ¤íŠ¸
        """
        # ìƒˆ ë°ì´í„°ì— random weight í• ë‹¹ (0~1 ì‚¬ì´ì˜ ê°’)
        new_weights = torch.rand(len(new_data))

        # ğŸ£ ìˆ˜ì •: ë°ì´í„°ì™€ ë ˆì´ë¸”ì„ íŠœí”Œë¡œ ë¬¶ì–´ì„œ ì €ì¥
        new_buffer = list(zip(new_data, new_labels))
        combined_buffer = self.buffer + new_buffer
        
        # ê¸°ì¡´ weightsì™€ ìƒˆ weights ê²°í•©
        cat_weights = torch.cat([self._buffer_weights, new_weights])  # ğŸŒ½ ìˆœì„œ í†µì¼!
        # weight ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        sorted_weights, sorted_idxs = cat_weights.sort(descending=True)

        # ìƒìœ„ max_sizeê°œë§Œ ì„ íƒ
        buffer_idxs = sorted_idxs[: self.max_size]
        # ì„ íƒëœ ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë§Œ ìœ ì§€
        self.buffer = [combined_buffer[i] for i in buffer_idxs.tolist()]  # ğŸ£ ìˆ˜ì •
        self._buffer_weights = sorted_weights[: self.max_size]

    def resize(self, new_size: int):  # ğŸŒ• Avalanche ë¼ì¸ 121-128 ê·¸ëŒ€ë¡œ
        """
        ë²„í¼ì˜ ìµœëŒ€ í¬ê¸°ë¥¼ ë³€ê²½í•©ë‹ˆë‹¤.
        í¬ê¸°ê°€ ì¤„ì–´ë“  ê²½ìš°, weightê°€ ë†’ì€ ìˆœì„œë¡œ ë°ì´í„°ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.
        
        :param new_size: ìƒˆë¡œìš´ ìµœëŒ€ í¬ê¸°
        """
        self.max_size = new_size
        if len(self.buffer) <= self.max_size:
            return
        # ì´ë¯¸ ì •ë ¬ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì•ì—ì„œë¶€í„° ìë¥´ë©´ ë¨
        self.buffer = self.buffer[: self.max_size]
        self._buffer_weights = self._buffer_weights[: self.max_size]
    
    # ğŸ£ ì¶”ê°€ ë©”ì„œë“œ
    def sample(self, n: int) -> Tuple[List, List]:
        """
        ë²„í¼ì—ì„œ nê°œì˜ ìƒ˜í”Œì„ ë¬´ì‘ìœ„ë¡œ ì„ íƒí•©ë‹ˆë‹¤.
        
        :param n: ì„ íƒí•  ìƒ˜í”Œ ìˆ˜
        :return: (ë°ì´í„° ë¦¬ìŠ¤íŠ¸, ë ˆì´ë¸” ë¦¬ìŠ¤íŠ¸) íŠœí”Œ
        """
        if not self.buffer:
            return [], []
        
        # ìš”ì²­ëœ ìˆ˜ì™€ ë²„í¼ í¬ê¸° ì¤‘ ì‘ì€ ê°’ ì„ íƒ
        n = min(n, len(self.buffer))
        # ë¬´ì‘ìœ„ ìˆœì—´ ìƒì„± (ì¤‘ë³µ ì—†ì´ ìƒ˜í”Œë§)
        indices = torch.randperm(len(self.buffer))[:n].tolist()
        
        sampled_data = []
        sampled_labels = []
        for i in indices:
            data, label = self.buffer[i]
            sampled_data.append(data)
            sampled_labels.append(label)
            
        return sampled_data, sampled_labels


class ClassBalancedBuffer:  # ğŸŒ• Avalanche storage_policy.py ë¼ì¸ 239-334 ê¸°ë°˜
    """
    í´ë˜ìŠ¤ë³„ë¡œ ê· ë“±í•˜ê²Œ ìƒ˜í”Œì„ ì €ì¥í•˜ëŠ” ë²„í¼ì…ë‹ˆë‹¤.
    
    ê° í´ë˜ìŠ¤ë§ˆë‹¤ ë…ë¦½ì ì¸ ReservoirSamplingBufferë¥¼ ìœ ì§€í•˜ì—¬,
    ëª¨ë“  í´ë˜ìŠ¤ê°€ ë©”ëª¨ë¦¬ì—ì„œ ê³µí‰í•˜ê²Œ í‘œí˜„ë˜ë„ë¡ í•©ë‹ˆë‹¤.
    
    ğŸ£ ì¶”ê°€ ê¸°ëŠ¥: ê° í´ë˜ìŠ¤ë³„ ìµœì†Œ ìƒ˜í”Œ ìˆ˜ ë³´ì¥
    """

    def __init__(
        self,
        max_size: int,
        adaptive_size: bool = True,
        total_num_classes: Optional[int] = None,
        min_samples_per_class: int = 10  # ğŸ£ ì¶”ê°€
    ):
        """
        :param max_size: ì „ì²´ ë²„í¼ì˜ ìµœëŒ€ ìš©ëŸ‰
        :param adaptive_size: Trueë©´ ìƒˆë¡œìš´ í´ë˜ìŠ¤ê°€ ì¶”ê°€ë  ë•Œë§ˆë‹¤ 
                             ê° í´ë˜ìŠ¤ì˜ í• ë‹¹ëŸ‰ì„ ë™ì ìœ¼ë¡œ ì¡°ì •
        :param total_num_classes: adaptive_sizeê°€ Falseì¼ ë•Œ, 
                                 ë¯¸ë¦¬ ì•Œê³  ìˆëŠ” ì „ì²´ í´ë˜ìŠ¤ ìˆ˜
        :param min_samples_per_class: ğŸ£ ê° í´ë˜ìŠ¤ë³„ ìµœì†Œ ìƒ˜í”Œ ìˆ˜ ë³´ì¥
        """
        self.max_size = max_size
        self.adaptive_size = adaptive_size
        self.total_num_classes = total_num_classes
        self.min_samples_per_class = min_samples_per_class  # ğŸ£
        self.seen_classes: Set[int] = set()  # ì§€ê¸ˆê¹Œì§€ ë³¸ í´ë˜ìŠ¤ë“¤
        self.buffer_groups: Dict[int, ReservoirSamplingBuffer] = {}  # í´ë˜ìŠ¤ë³„ ë²„í¼
        
        # ğŸ’ ì»¤ë²„ë¦¬ì§€ ìƒ˜í”Œë§ì„ ìœ„í•œ í ì¶”ê°€
        self._cov_queues = defaultdict(deque)  # í´ë˜ìŠ¤ë³„ exemplar í
        self._cov_classes = []  # í˜„ì¬ í´ë˜ìŠ¤ ìˆœì„œ
        self.experience_count = 0  # ğŸ’ ê²½í—˜ ì¹´ìš´í„° (ë¡œê·¸ìš©)

    def get_group_lengths(self, num_groups):  # ğŸŒ• + ğŸ£ ìµœì†Œ ë³´ì¥ ë¡œì§ ì¶”ê°€
        """
        ê° í´ë˜ìŠ¤(ê·¸ë£¹)ì— í• ë‹¹ë  ë²„í¼ í¬ê¸°ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        :param num_groups: í˜„ì¬ê¹Œì§€ ë³¸ í´ë˜ìŠ¤ ìˆ˜
        :return: ê° í´ë˜ìŠ¤ë³„ í• ë‹¹ í¬ê¸° ë¦¬ìŠ¤íŠ¸
        """
        if self.adaptive_size:
            # ğŸ£ ìµœì†Œ ë³´ì¥ ê³„ì‚°
            guaranteed_size = num_groups * self.min_samples_per_class
            if guaranteed_size > self.max_size:
                # ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•œ ê²½ìš°: ê· ë“± ë¶„ë°° (ìµœì†Œ ë³´ì¥ í¬ê¸°)
                return [self.max_size // num_groups for _ in range(num_groups)]
            
            # ìµœì†Œ ë³´ì¥ í›„ ë‚¨ì€ ê³µê°„ì„ ê· ë“± ë¶„ë°°
            remaining = self.max_size - guaranteed_size
            base_size = remaining // num_groups
            extra = remaining % num_groups  # ë‚˜ë¨¸ì§€ëŠ” ì•ìª½ í´ë˜ìŠ¤ì— 1ê°œì”© ì¶”ê°€
            
            lengths = []
            for i in range(num_groups):
                size = self.min_samples_per_class + base_size
                if i < extra:
                    size += 1
                lengths.append(size)
            return lengths
        else:
            # Fixed size: ì „ì²´ í´ë˜ìŠ¤ ìˆ˜ë¡œ ê· ë“± ë¶„ë°°
            lengths = [
                self.max_size // self.total_num_classes for _ in range(num_groups)
            ]
        return lengths

    def update_from_dataset(
        self, new_data: List, new_labels: List  # ğŸ£ ìˆ˜ì •: List ì…ë ¥
    ):
        """
        ìƒˆë¡œìš´ ë°ì´í„°ë¡œ ë²„í¼ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        
        :param new_data: ìƒˆë¡œìš´ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        :param new_labels: ìƒˆë¡œìš´ ë ˆì´ë¸” ë¦¬ìŠ¤íŠ¸
        """

        print(f"\n=== Memory Buffer Update Debug ===")
        print(f"new_data type: {type(new_data)}, len: {len(new_data)}")
        print(f"new_labels type: {type(new_labels)}, len: {len(new_labels)}")

        if len(new_data) == 0:
            return

        # í´ë˜ìŠ¤ë³„ë¡œ ë°ì´í„° ì¸ë±ìŠ¤ ìˆ˜ì§‘
        cl_idxs: Dict[int, List[int]] = defaultdict(list)
        for idx, label in enumerate(new_labels):
            # tensorì¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ intë¡œ ë³€í™˜
            label = int(label)
            cl_idxs[label].append(idx)

         # ë””ë²„ê¹… ì¶œë ¥ ì¶”ê°€
        print(f"cl_idxs keys: {list(cl_idxs.keys())}")
        for key, idxs in cl_idxs.items():
            print(f"  class {key}: {len(idxs)} indices = {idxs}")
        print(f"Max index needed: {max(max(idxs) for idxs in cl_idxs.values())}")
        print(f"new_data length: {len(new_data)}")
        
        # í´ë˜ìŠ¤ë³„ë¡œ ë°ì´í„° ë¶„ë¦¬
        cl_datasets = {}
        for c, c_idxs in cl_idxs.items():
            # í•´ë‹¹ í´ë˜ìŠ¤ì˜ ë°ì´í„°ì™€ ë ˆì´ë¸” ì¶”ì¶œ
            cl_datasets[c] = ([new_data[i] for i in c_idxs], 
                             [new_labels[i] for i in c_idxs])  # ğŸ£ ìˆ˜ì •

        # ìƒˆë¡œ ë³¸ í´ë˜ìŠ¤ ì¶”ê°€
        self.seen_classes.update(cl_datasets.keys())

        # ê° í´ë˜ìŠ¤ë³„ í• ë‹¹ í¬ê¸° ê³„ì‚°
        lens = self.get_group_lengths(len(self.seen_classes))
        class_to_len = {}
        # í´ë˜ìŠ¤ ID ìˆœì„œëŒ€ë¡œ í¬ê¸° í• ë‹¹ (ì¼ê´€ì„±ì„ ìœ„í•´ ì •ë ¬)
        for class_id, ll in zip(sorted(self.seen_classes), lens):  # ğŸ£ sorted ì¶”ê°€
            class_to_len[class_id] = ll

        # ê° í´ë˜ìŠ¤ë³„ë¡œ ë²„í¼ ì—…ë°ì´íŠ¸
        for class_id, (data_c, labels_c) in cl_datasets.items():  # ğŸ£ ìˆ˜ì •
            ll = class_to_len[class_id]
            if class_id in self.buffer_groups:
                # ê¸°ì¡´ í´ë˜ìŠ¤: ë²„í¼ ì—…ë°ì´íŠ¸
                old_buffer_c = self.buffer_groups[class_id]
                old_buffer_c.update_from_dataset(data_c, labels_c)  # ğŸ£ ìˆ˜ì •
                old_buffer_c.resize(ll)
            else:
                # ìƒˆ í´ë˜ìŠ¤: ë²„í¼ ìƒì„±
                new_buffer = ReservoirSamplingBuffer(ll)
                new_buffer.update_from_dataset(data_c, labels_c)  # ğŸ£ ìˆ˜ì •
                self.buffer_groups[class_id] = new_buffer

        # ëª¨ë“  ë²„í¼ì˜ í¬ê¸° ì¬ì¡°ì • (ìƒˆ í´ë˜ìŠ¤ ì¶”ê°€ë¡œ ì¸í•œ ì¬ë¶„ë°°)
        for class_id, class_buf in self.buffer_groups.items():
            self.buffer_groups[class_id].resize(class_to_len[class_id])
    
    # ğŸ£ ì¶”ê°€ ë©”ì„œë“œë“¤
    def sample(self, n: int) -> Tuple[List, List]:
        """
        ëª¨ë“  í´ë˜ìŠ¤ì—ì„œ ê· ë“±í•˜ê²Œ nê°œì˜ ìƒ˜í”Œì„ ì„ íƒí•©ë‹ˆë‹¤.
        
        :param n: ì„ íƒí•  ì´ ìƒ˜í”Œ ìˆ˜
        :return: (ë°ì´í„° ë¦¬ìŠ¤íŠ¸, ë ˆì´ë¸” ë¦¬ìŠ¤íŠ¸) íŠœí”Œ
        """
        if not self.buffer_groups:
            return [], []
        
        # ê° í´ë˜ìŠ¤ì—ì„œ ë½‘ì„ ìƒ˜í”Œ ìˆ˜ ê³„ì‚°
        samples_per_class = n // len(self.buffer_groups)
        remainder = n % len(self.buffer_groups)
        
        all_data = []
        all_labels = []
        
        for i, (class_id, buffer) in enumerate(self.buffer_groups.items()):
            n_samples = samples_per_class
            # ë‚˜ë¨¸ì§€ë¥¼ ì•ìª½ í´ë˜ìŠ¤ì— 1ê°œì”© ì¶”ê°€
            if i < remainder:
                n_samples += 1
                
            data, labels = buffer.sample(n_samples)
            all_data.extend(data)
            all_labels.extend(labels)
        
        # í´ë˜ìŠ¤ ìˆœì„œê°€ ì˜ˆì¸¡ ê°€ëŠ¥í•˜ì§€ ì•Šë„ë¡ ì„ê¸°
        if all_data:
            indices = torch.randperm(len(all_data)).tolist()
            shuffled_data = [all_data[i] for i in indices]
            shuffled_labels = [all_labels[i] for i in indices]
            return shuffled_data, shuffled_labels
        
        return all_data, all_labels
    
    # ğŸ’ ì»¤ë²„ë¦¬ì§€ ìƒ˜í”Œë§ ë©”ì„œë“œ ì¶”ê°€ - ì§„ì§œ per-exemplar ìˆœí™˜
    def _reset_class_queue(self, cls):
        """ğŸ’ í´ë˜ìŠ¤ì˜ exemplar íë¥¼ ë¦¬ì…‹ (ì—í­ ì‹œì‘)"""
        if cls not in self.buffer_groups:
            return
        
        buf = self.buffer_groups[cls].buffer
        if not buf:
            return
            
        idxs = list(range(len(buf)))
        random.shuffle(idxs)  # ì—í­ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ì…”í”Œ
        self._cov_queues[cls] = deque(idxs)
    
    def coverage_sample(self, n: int, k_per_class: int = 2) -> Tuple[List, List]:
        """
        ğŸ’ ëª¨ë“  exemplarë¥¼ ê³µí‰í•˜ê²Œ ìˆœí™˜í•˜ëŠ” ì»¤ë²„ë¦¬ì§€ ìƒ˜í”Œë§
        
        ê° í´ë˜ìŠ¤ì˜ ëª¨ë“  exemplarê°€ í•œ ë²ˆì”© ì‚¬ìš©ë˜ê¸° ì „ì—ëŠ”
        ê°™ì€ exemplarê°€ ë°˜ë³µë˜ì§€ ì•ŠìŒ (ì§„ì§œ ìˆœí™˜)
        
        :param n: ì´ ìƒ˜í”Œ ìˆ˜
        :param k_per_class: í´ë˜ìŠ¤ë‹¹ ìƒ˜í”Œ ìˆ˜
        :return: (paths, labels)
        """
        if not self.buffer_groups:
            return [], []
        
        # ğŸ’ í´ë˜ìŠ¤ ëª©ë¡ ë³€ê²½ ê°ì§€ â†’ í/ìˆœì„œ ê°±ì‹ 
        classes_now = list(self.buffer_groups.keys())
        if set(classes_now) != set(self._cov_classes):
            self._cov_classes = classes_now[:]
            random.shuffle(self._cov_classes)
            
            # ëª¨ë“  í´ë˜ìŠ¤ í ì´ˆê¸°í™”
            for cls in self._cov_classes:
                self._reset_class_queue(cls)
            
            print(f"ğŸ’ Coverage sampler initialized: {len(self._cov_classes)} classes")
        
        paths = []
        labels = []
        ci = 0  # í´ë˜ìŠ¤ ì¸ë±ìŠ¤
        
        while len(paths) < n and self._cov_classes:
            cls = self._cov_classes[ci % len(self._cov_classes)]
            ci += 1
            
            buf = self.buffer_groups[cls].buffer
            if not buf:
                continue
            
            # ğŸ’ í´ë˜ìŠ¤ì—ì„œ k_per_classê°œ ì¶”ì¶œ
            take = min(k_per_class, len(buf), n - len(paths))
            
            for _ in range(take):
                # ğŸ’ íê°€ ë¹„ë©´ ë¦¬ì…‹ (í•œ ë°”í€´ ì™„ë£Œ!)
                if not self._cov_queues[cls]:
                    self._reset_class_queue(cls)
                    
                    # ğŸ’ ìˆœí™˜ ê²€ì¦ ë¡œê·¸ (10 experienceë§ˆë‹¤)
                    if self.experience_count > 0 and self.experience_count % 10 == 0:
                        print(f"â™»ï¸ Class {cls} completed full cycle (all {len(buf)} exemplars used)")
                
                # ğŸ’ íì—ì„œ ì¸ë±ìŠ¤ pop (ì¤‘ë³µ ì—†ìŒ ë³´ì¥!)
                j = self._cov_queues[cls].popleft()
                j = min(j, len(buf) - 1)  # ë²”ìœ„ ì•ˆì „
                
                p, y = buf[j]
                paths.append(p)
                labels.append(y)
                
                if len(paths) >= n:
                    break
        
        return paths[:n], labels[:n]
    
    def set_experience_count(self, count):
        """ğŸ’ ê²½í—˜ ì¹´ìš´í„° ì„¤ì • (ë¡œê·¸ìš©)"""
        self.experience_count = count

    # ClassBalancedBufferì— ì¶”ê°€ í•„ìš”
    def get_all_data(self) -> Tuple[List, List]:
        """ë²„í¼ì˜ ëª¨ë“  ë°ì´í„°ë¥¼ ë°˜í™˜"""
        all_data = []
        all_labels = []
        
        for buffer in self.buffer_groups.values():
            for data, label in buffer.buffer:
                all_data.append(data)
                all_labels.append(label)
        
        return all_data, all_labels
    
    def __len__(self):
        """ë²„í¼ì— ì €ì¥ëœ ì´ ìƒ˜í”Œ ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return sum(len(buffer.buffer) for buffer in self.buffer_groups.values())