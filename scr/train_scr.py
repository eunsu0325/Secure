#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Supervised Contrastive Replay (SCR) Training Script with Open-set Support
CCNet + SCR for Continual Learning
ü¶à ProxyAnchorLoss Support Added
‚≠êÔ∏è Energy Score Support Added
üéØ TTA Support Added
ü´ê TTA Repeats Support Added
üéæ Type-specific TTA Repeats & Impostor Ratios Added
"""

import os
import argparse
import time
import numpy as np
from collections import defaultdict
from typing import Dict, List
import json
import random

import torch
from torch.utils.data import DataLoader, Subset

# Project imports
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import ConfigParser
from utils.pretrained_loader import PretrainedLoader

# ÏãúÍ∞ÅÌôî Í¥ÄÎ†®
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from sklearn.manifold import TSNE
from PIL import Image
import torch.nn.functional as F

from models import ccnet, MyDataset, get_scr_transforms
from scr import (
    ExperienceStream, 
    ClassBalancedBuffer, 
    NCMClassifier, 
    SCRTrainer
)

# ü•© Ïò§ÌîàÏÖã Ìï®ÏàòÎì§ import Ï∂îÍ∞Ä
try:
    from utils.utils_openset import (
        predict_batch,
        predict_batch_tta,
        load_paths_labels_from_txt
    )
    TTA_AVAILABLE = True
except ImportError:
    from utils.utils_openset import (
        predict_batch,
        load_paths_labels_from_txt
    )
    TTA_AVAILABLE = False
    print("‚ö†Ô∏è TTA functions not available")

def compute_safe_base_id(*txt_files):
    """Î™®Îì† txt ÌååÏùºÏóêÏÑú ÏµúÎåÄ user IDÎ•º Ï∞æÏïÑ ÏïàÏ†ÑÌïú BASE_ID Í≥ÑÏÇ∞"""
    max_id = 0
    for path in txt_files:
        with open(path, 'r', encoding='utf-8') as fh:
            for line in fh:
                parts = line.strip().split()
                if len(parts) != 2:
                    continue
                try:
                    lab = int(parts[1])
                except ValueError:
                    continue
                max_id = max(max_id, lab)
    base = max_id + 1
    print(f"[NEG-BASE] max_user_id={max_id}, BASE_ID={base}")
    return base

def purge_negatives(memory_buffer, base_id):
    """Î©îÎ™®Î¶¨ Î≤ÑÌçºÏóêÏÑú Î™®Îì† ÎÑ§Í±∞Ìã∞Î∏å ÌÅ¥ÎûòÏä§ Ï†úÍ±∞"""
    to_del = [int(c) for c in list(memory_buffer.seen_classes) if int(c) >= base_id]
    removed = 0
    for c in to_del:
        if c in memory_buffer.buffer_groups:
            removed += len(memory_buffer.buffer_groups[c].buffer)
            del memory_buffer.buffer_groups[c]
        memory_buffer.seen_classes.discard(c)
    print(f"üßπ Purged {len(to_del)} negative classes ({removed} samples)")

def remove_negative_samples_gradually(memory_buffer: ClassBalancedBuffer, 
                                    base_id: int,
                                    removal_ratio: float = 0.2):
    """Î©îÎ™®Î¶¨ Î≤ÑÌçºÏóêÏÑú negative ÏÉòÌîåÏùÑ Ï†êÏßÑÏ†ÅÏúºÎ°ú Ï†úÍ±∞"""
    negative_classes = [int(c) for c in memory_buffer.seen_classes if int(c) >= base_id]
    
    if not negative_classes:
        return 0
    
    num_to_remove = max(1, int(len(negative_classes) * removal_ratio))
    classes_to_remove = np.random.choice(negative_classes, size=num_to_remove, replace=False)
    
    removed_count = 0
    for class_id in classes_to_remove:
        if class_id in memory_buffer.buffer_groups:
            removed_count += len(memory_buffer.buffer_groups[class_id].buffer)
            del memory_buffer.buffer_groups[class_id]
            memory_buffer.seen_classes.remove(class_id)
    
    print(f"Removed {num_to_remove} negative classes ({removed_count} samples)")
    return removed_count

@torch.no_grad()
def plot_tsne_from_memory(trainer,
                          save_path,
                          per_class=150,
                          space='fe',
                          perplexity=30,
                          max_points=5000,
                          seed=42):
    """Î©îÎ™®Î¶¨ Î≤ÑÌçºÏùò ÏûÑÎ≤†Îî©ÏùÑ t-SNEÎ°ú ÏãúÍ∞ÅÌôî"""
    model = trainer.model
    model.eval()
    device = trainer.device
    
    paths, labels = trainer.memory_buffer.get_all_data()
    if len(paths) == 0:
        print("[t-SNE] Memory buffer is empty.")
        return
    
    base_id = getattr(trainer, 'base_id', 
                     getattr(trainer.config.negative, 'base_id', 10000))
    real_data = [(p, l) for p, l in zip(paths, labels) 
                 if int(l) < base_id]
    
    if len(real_data) == 0:
        print("[t-SNE] No real users in buffer.")
        return
    
    from collections import defaultdict
    by_cls = defaultdict(list)
    for p, y in real_data:
        by_cls[int(y)].append(p)
    
    rng = random.Random(seed)
    sampled = []
    for c, lst in by_cls.items():
        k = min(per_class, len(lst))
        sampled += [(p, c) for p in rng.sample(lst, k)]
    
    if len(sampled) > max_points:
        sampled = rng.sample(sampled, max_points)
    
    print(f"[t-SNE] Processing {len(sampled)} samples from {len(by_cls)} classes")
    
    transform = trainer.test_transform
    ch = trainer.config.dataset.channels
    
    batch_size = 128
    features_list = []
    labels_list = []
    
    for i in range(0, len(sampled), batch_size):
        batch = sampled[i:i+batch_size]
        
        imgs = []
        for path, _ in batch:
            with Image.open(path) as img:
                img = img.convert('L' if ch == 1 else 'RGB')
                imgs.append(transform(img))
        
        imgs = torch.stack(imgs).to(device)
        features = model(imgs)
        
        if space == 'z' and hasattr(model, 'projection_head'):
            features = F.normalize(model.projection_head(features), dim=-1)
        
        features_list.append(features.cpu())
        labels_list.extend([y for _, y in batch])
    
    X = torch.cat(features_list, dim=0).numpy()
    Y = np.array(labels_list)
    
    perplexity = min(perplexity, max(5, len(Y)//4))
    
    print(f"[t-SNE] Running t-SNE with perplexity={perplexity}...")
    tsne = TSNE(
        n_components=2,
        perplexity=perplexity,
        n_iter=1500,
        metric='euclidean',
        init='pca',
        learning_rate='auto',
        random_state=seed,
        verbose=0
    )
    
    Z = tsne.fit_transform(X)
    
    plt.figure(figsize=(12, 8))
    
    n_classes = len(set(Y))
    cmap = cm.get_cmap('tab20' if n_classes <= 20 else 'hsv', n_classes)
    
    for idx, c in enumerate(sorted(set(Y))):
        mask = (Y == c)
        color = cmap(idx)
        plt.scatter(
            Z[mask, 0], Z[mask, 1],
            c=[color],
            s=15,
            alpha=0.7,
            edgecolors='none',
            label=f'User {c}' if n_classes <= 10 else None
        )
    
    plt.title(f't-SNE Visualization ({space.upper()}) | {n_classes} classes, {len(Y)} points', 
              fontsize=14, fontweight='bold')
    plt.axis('off')
    
    if n_classes <= 10:
        plt.legend(loc='best', markerscale=2)
    
    plt.tight_layout()
    
    os.makedirs(os.path.dirname(save_path) if os.path.dirname(save_path) else '.', exist_ok=True)
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"[t-SNE] Saved to {save_path}")

class ContinualLearningEvaluator:
    """
    Continual Learning ÌèâÍ∞Ä Î©îÌä∏Î¶≠ Í≥ÑÏÇ∞
    - Average Accuracy
    - Forgetting Measure
    - Open-set metrics (TAR, TRR, FAR)
    """
    def __init__(self, num_experiences: int):
        self.num_experiences = num_experiences
        self.accuracy_history = defaultdict(list)
        self.openset_history = []
        
    def update(self, experience_id: int, accuracy: float):
        """experience_id ÌïôÏäµ ÌõÑ Ï†ïÌôïÎèÑ ÏóÖÎç∞Ïù¥Ìä∏"""
        self.accuracy_history[experience_id].append(accuracy)
    
    def update_openset(self, metrics: dict):
        """Ïò§ÌîàÏÖã Î©îÌä∏Î¶≠ ÏóÖÎç∞Ïù¥Ìä∏"""
        self.openset_history.append(metrics)
    
    def get_average_accuracy(self) -> float:
        """ÌòÑÏû¨ÍπåÏßÄÏùò ÌèâÍ∑† Ï†ïÌôïÎèÑ"""
        all_accs = []
        for accs in self.accuracy_history.values():
            if accs:
                all_accs.append(accs[-1])
        return np.mean(all_accs) if all_accs else 0.0
    
    def get_forgetting_measure(self) -> float:
        """Forgetting Measure Í≥ÑÏÇ∞"""
        forgetting = []
        for exp_id, accs in self.accuracy_history.items():
            if len(accs) > 1:
                max_acc = max(accs[:-1])
                curr_acc = accs[-1]
                forgetting.append(max_acc - curr_acc)
        
        return np.mean(forgetting) if forgetting else 0.0
    
    def get_latest_openset_metrics(self) -> dict:
        """ÏµúÏã† Ïò§ÌîàÏÖã Î©îÌä∏Î¶≠ Î∞òÌôò"""
        if self.openset_history:
            return self.openset_history[-1]
        return {}


def evaluate_on_test_set(trainer: SCRTrainer, config, openset_mode=False) -> tuple:
    """
    test_set_fileÏùÑ ÏÇ¨Ïö©Ìïú Ï†ÑÏ≤¥ ÌèâÍ∞Ä
    openset_mode=TrueÎ©¥ Ïò§ÌîàÏÖã ÌèâÍ∞ÄÎèÑ ÏàòÌñâ
    ü•© TTA ÏßÄÏõê Ï∂îÍ∞Ä
    
    Returns:
        (accuracy, openset_metrics) if openset_mode else (accuracy, None)
    """
    test_dataset = MyDataset(
        txt=config.dataset.test_set_file,
        transforms=get_scr_transforms(
            train=False,
            imside=config.dataset.height,
            channels=config.dataset.channels
        ),
        train=False,
        imside=config.dataset.height,
        outchannels=config.dataset.channels
    )
    
    known_classes = set(trainer.ncm.class_means_dict.keys())
    
    if not known_classes:
        return (0.0, {}) if openset_mode else (0.0, None)
    
    # ü•© TTA ÏÑ§Ï†ï ÌôïÏù∏
    use_tta = (TTA_AVAILABLE and 
               hasattr(trainer, 'use_tta') and trainer.use_tta and 
               hasattr(config, 'openset') and config.openset.tta_n_views > 1)
    
    if openset_mode and trainer.openset_enabled:
        known_indices = []
        unknown_indices = []
        
        for i in range(len(test_dataset)):
            label = int(test_dataset.images_label[i])
            if label in known_classes:
                known_indices.append(i)
            else:
                unknown_indices.append(i)
        
        if known_indices:
            known_subset = Subset(test_dataset, known_indices)
            accuracy = trainer.evaluate(known_subset)
        else:
            accuracy = 0.0
        
        openset_metrics = {}
        
        if known_indices and trainer.ncm.tau_s is not None:
            if len(known_indices) > 500:
                known_indices = np.random.choice(known_indices, 500, replace=False)
            
            known_paths = [test_dataset.images_path[i] for i in known_indices] 
            known_labels = [int(test_dataset.images_label[i]) for i in known_indices]
            
            # ü•© TTA ÎòêÎäî ÏùºÎ∞ò ÏòàÏ∏°
            if use_tta:
                preds = predict_batch_tta(
                    trainer.model, trainer.ncm,
                    known_paths, trainer.test_transform, trainer.device,
                    n_views=config.openset.tta_n_views,
                    include_original=config.openset.tta_include_original,
                    agree_k=config.openset.tta_agree_k,
                    aug_strength=config.openset.tta_augmentation_strength,
                    img_size=config.dataset.height,
                    channels=config.dataset.channels  # ü´ê Ï∂îÍ∞Ä
                )
            else:
                preds = predict_batch(
                    trainer.model, trainer.ncm,
                    known_paths, trainer.test_transform, trainer.device,
                    channels=config.dataset.channels  # ü´ê Ï∂îÍ∞Ä
                )
            
            correct = sum(1 for p, l in zip(preds, known_labels) if p == l)
            rejected = sum(1 for p in preds if p == -1)
            
            openset_metrics['TAR'] = correct / max(1, len(preds))
            openset_metrics['FRR'] = rejected / max(1, len(preds))
        
        if unknown_indices and trainer.ncm.tau_s is not None:
            if len(unknown_indices) > 500:
                unknown_indices = np.random.choice(unknown_indices, 500, replace=False)
            
            unknown_paths = [test_dataset.images_path[i] for i in unknown_indices]
            
            # ü•© TTA ÎòêÎäî ÏùºÎ∞ò ÏòàÏ∏°
            if use_tta:
                preds = predict_batch_tta(
                    trainer.model, trainer.ncm,
                    unknown_paths, trainer.test_transform, trainer.device,
                    n_views=config.openset.tta_n_views,
                    include_original=config.openset.tta_include_original,
                    agree_k=config.openset.tta_agree_k,
                    aug_strength=config.openset.tta_augmentation_strength,
                    img_size=config.dataset.height,
                    channels=config.dataset.channels  # ü•© Ï∂îÍ∞Ä
                )
            else:
                preds = predict_batch(
                    trainer.model, trainer.ncm,
                    unknown_paths, trainer.test_transform, trainer.device,
                    channels=config.dataset.channels  # ü•© Ï∂îÍ∞Ä
                )
            
            openset_metrics['TRR_unknown'] = sum(1 for p in preds if p == -1) / len(preds)
            openset_metrics['FAR_unknown'] = 1 - openset_metrics['TRR_unknown']
        
        openset_metrics['tau_s'] = trainer.ncm.tau_s
        
        # ü•© TTA Ï†ïÎ≥¥ Ï∂îÍ∞Ä
        if use_tta:
            openset_metrics['tta_enabled'] = True
            openset_metrics['tta_views'] = config.openset.tta_n_views
            
            # üéæ ÌÉÄÏûÖÎ≥Ñ Î∞òÎ≥µ Ï†ïÎ≥¥ Ï∂îÍ∞Ä
            openset_metrics['tta_repeats_genuine'] = config.openset.tta_n_repeats_genuine
            openset_metrics['tta_repeats_between'] = config.openset.tta_n_repeats_between
            openset_metrics['tta_repeats_negref'] = config.openset.tta_n_repeats_negref
            openset_metrics['tta_repeat_aggregation'] = config.openset.tta_repeat_aggregation
        else:
            openset_metrics['tta_enabled'] = False
        
        print(f"Evaluating on {len(known_indices)} known + {len(unknown_indices)} unknown samples")
        if use_tta:
            print(f"   üéØ Using TTA with {config.openset.tta_n_views} views")
            # üéæ ÌÉÄÏûÖÎ≥Ñ Î∞òÎ≥µ Ï†ïÎ≥¥ Ï∂úÎ†•
            print(f"   üîÑ Type-specific repeats: G={config.openset.tta_n_repeats_genuine}, "
                  f"B={config.openset.tta_n_repeats_between}, N={config.openset.tta_n_repeats_negref}")
        
        return accuracy, openset_metrics
    
    else:
        filtered_indices = []
        for i in range(len(test_dataset)):
            label = int(test_dataset.images_label[i])
            if label in known_classes:
                filtered_indices.append(i)
        
        if not filtered_indices:
            return (0.0, None)
        
        filtered_test = Subset(test_dataset, filtered_indices)
        
        print(f"Evaluating on {len(filtered_indices)} test samples from {len(known_classes)} classes")
        
        accuracy = trainer.evaluate(filtered_test)
        return accuracy, None


def main(args):
    """Î©îÏù∏ Ïã§Ìñâ Ìï®Ïàò"""
    
    # 1. Configuration Î°úÎìú
    config = ConfigParser(args.config)
    config_obj = config.get_config()
    print(f"Using config: {args.config}")
    print(config)
    
    # ü•© configÏóê seed ÏÑ§Ï†ï Ï∂îÍ∞Ä (SCRTrainerÍ∞Ä ÏÇ¨Ïö©)
    if not hasattr(config_obj.training, 'seed'):
        config_obj.training.seed = args.seed
    
    # BASE_ID Í≥ÑÏÇ∞ Î∞è ÏÑ§Ï†ï
    config_obj.negative.base_id = compute_safe_base_id(
        config_obj.dataset.train_set_file,
        config_obj.dataset.test_set_file
    )
    
    # Ïò§ÌîàÏÖã Î™®Îìú ÌôïÏù∏
    openset_enabled = hasattr(config_obj, 'openset') and config_obj.openset.enabled
    if openset_enabled:
        print("\nüêã ========== OPEN-SET MODE ENABLED ==========")
        print(f"   Warmup users: {config_obj.openset.warmup_users}")
        print(f"   Initial tau: {config_obj.openset.initial_tau}")
        
        # ü•© TTA Ï†ïÎ≥¥ Ï∂îÍ∞Ä
        if config_obj.openset.tta_n_views > 1:
            print(f"   üéØ TTA: {config_obj.openset.tta_n_views} views")
            print(f"      Include original: {config_obj.openset.tta_include_original}")
            print(f"      Augmentation: {config_obj.openset.tta_augmentation_strength}")
            print(f"      Aggregation: {config_obj.openset.tta_aggregation}")
            
            # üéæ ÌÉÄÏûÖÎ≥Ñ TTA Î∞òÎ≥µ Ï†ïÎ≥¥ Ï∂îÍ∞Ä
            print(f"   üîÑ Type-specific TTA Repeats:")
            print(f"      Genuine: {config_obj.openset.tta_n_repeats_genuine} repeats")
            print(f"      Between: {config_obj.openset.tta_n_repeats_between} repeats")
            print(f"      NegRef: {config_obj.openset.tta_n_repeats_negref} repeats")
            print(f"      Repeat aggregation: {config_obj.openset.tta_repeat_aggregation}")
        
        # üéæ Impostor ÎπÑÏú® Ï†ïÎ≥¥ Ï∂îÍ∞Ä
        print(f"   üìä Impostor Ratios:")
        print(f"      Between: {config_obj.openset.impostor_ratio_between*100:.0f}%")
        print(f"      Unknown: {config_obj.openset.impostor_ratio_unknown*100:.0f}%")
        print(f"      NegRef: {config_obj.openset.impostor_ratio_negref*100:.0f}%")
        print(f"      Total samples: {config_obj.openset.impostor_balance_total}")
        
        # FAR/EER Î™®Îìú ÌëúÏãú
        if config_obj.openset.threshold_mode == 'far':
            print(f"   Threshold mode: FAR Target ({config_obj.openset.target_far*100:.1f}%)")
        else:
            print(f"   Threshold mode: EER")
        
        print("üêã =========================================\n")
    
    # ü¶à ProxyAnchorLoss ÏÑ§Ï†ï ÌôïÏù∏
    if hasattr(config_obj.training, 'use_proxy_anchor') and config_obj.training.use_proxy_anchor:
        print("\nü¶à ========== PROXY ANCHOR LOSS ENABLED ==========")
        print(f"   Margin (Œ¥): {config_obj.training.proxy_margin}")
        print(f"   Alpha (Œ±): {config_obj.training.proxy_alpha}")
        print(f"   LR Ratio: {config_obj.training.proxy_lr_ratio}x")
        print(f"   Lambda (fixed): {config_obj.training.proxy_lambda}")
        print("ü¶à ===============================================\n")
    
    # GPU ÏÑ§Ï†ï
    device = torch.device(
        f"cuda:{config_obj.training.gpu_ids}" 
        if torch.cuda.is_available() and not args.no_cuda 
        else "cpu"
    )
    print(f'Device: {device}')
    
    # 2. Í≤∞Í≥º Ï†ÄÏû• ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±
    results_dir = os.path.join(config_obj.training.results_path, 'scr_results')
    
    # 3. Îç∞Ïù¥ÌÑ∞ Ïä§Ìä∏Î¶º Ï¥àÍ∏∞Ìôî
    print("\n=== Initializing Data Stream ===")
    data_stream = ExperienceStream(
        train_file=config_obj.dataset.train_set_file,
        negative_file=config_obj.dataset.negative_samples_file,
        num_negative_classes=config_obj.dataset.num_negative_classes,
        base_id=config_obj.negative.base_id
    )
    
    stats = data_stream.get_statistics()
    print(f"Total users: {stats['num_users']}")
    print(f"Samples per user: {stats['samples_per_user']}")
    print(f"Negative samples: {stats['negative_samples']}")
    
    # 4. Î™®Îç∏ Î∞è Ïª¥Ìè¨ÎÑåÌä∏ Ï¥àÍ∏∞Ìôî
    print("\n=== Initializing Model and Components ===")
    
    # CCNet Î™®Îç∏
    model = ccnet(
        weight=config_obj.model.competition_weight,
        use_projection=config_obj.model.use_projection,
        projection_dim=config_obj.model.projection_dim
    )

    # ÌîÑÎ°úÏ†ùÏÖò Ìó§Îìú ÏÑ§Ï†ï Ï∂úÎ†•
    if config_obj.model.use_projection:
        print(f"üßÄ Projection Head Configuration:")
        print(f"   Enabled: True")
        print(f"   Dimension: 6144 -> 2048 -> {config_obj.model.projection_dim}")
        print(f"   Structure: 2 layers with LayerNorm")
        print(f"   Training: Uses projection ({config_obj.model.projection_dim}D)")
        print(f"   NCM/Eval: Uses original features (6144D)")
    else:
        print(f"üìå Projection Head: Disabled (using raw 6144D features)")
    
    # ÏÇ¨Ï†ÑÌõàÎ†® Í∞ÄÏ§ëÏπò Î°úÎìú
    if hasattr(config_obj.model, 'use_pretrained') and config_obj.model.use_pretrained:
        if config_obj.model.pretrained_path and config_obj.model.pretrained_path.exists():
            print(f"\nüì¶ Loading pretrained weights from main script...")
            loader = PretrainedLoader()
            try:
                model = loader.load_ccnet_pretrained(
                    model=model,
                    checkpoint_path=config_obj.model.pretrained_path,
                    device=device,
                    verbose=True
                )
                print("‚úÖ Pretrained weights loaded successfully!")
            except Exception as e:
                print(f"‚ö†Ô∏è  Failed to load pretrained model: {e}")
                print("Continuing with random initialization...")
        else:
            print(f"‚ö†Ô∏è  Pretrained path not found or not set")
    else:
        print("üé≤ Starting from random initialization")
    
    model = model.to(device)
    
    # NCM Classifier
    ncm_classifier = NCMClassifier(normalize=True).to(device)
    
    # Memory Buffer
    memory_buffer = ClassBalancedBuffer(
        max_size=config_obj.training.memory_size,
        min_samples_per_class=config_obj.training.min_samples_per_class
    )
    
    # SCR Trainer (ü•© Ïó¨Í∏∞ÏÑú ÏãúÎìúÍ∞Ä ÏÑ§Ï†ïÎê®)
    trainer = SCRTrainer(
        model=model,
        ncm_classifier=ncm_classifier,
        memory_buffer=memory_buffer,
        config=config_obj,
        device=device
    )
    
    # 5. Negative ÏÉòÌîåÎ°ú Ï¥àÍ∏∞Ìôî
    print("\n=== Initializing with Negative Samples ===")
    neg_paths, neg_labels = data_stream.get_negative_samples()
    
    if len(neg_paths) > config_obj.training.memory_batch_size:
        selected_indices = np.random.choice(
            len(neg_paths), 
            size=config_obj.training.memory_batch_size,
            replace=False
        )
        neg_paths = [neg_paths[i] for i in selected_indices]
        neg_labels = [neg_labels[i] for i in selected_indices]
    
    memory_buffer.update_from_dataset(neg_paths, neg_labels)
    print(f"Initial buffer size: {len(memory_buffer)}")
    
    print("üçÑ NCM starts empty - no fake class contamination")
    
    # 6. ÌèâÍ∞ÄÏûê Ï¥àÍ∏∞Ìôî
    evaluator = ContinualLearningEvaluator(num_experiences=config_obj.training.num_experiences)
    
    # 7. ÌïôÏäµ Í≤∞Í≥º Ï†ÄÏû•Ïö©
    training_history = {
        'losses': [],
        'accuracies': [],
        'forgetting_measures': [],
        'memory_sizes': [],
        'negative_removal_history': [],
        'openset_metrics': [],
        'pretrained_used': config_obj.model.use_pretrained,
        'pretrained_path': str(config_obj.model.pretrained_path) if config_obj.model.pretrained_path else None,
        'openset_enabled': openset_enabled,
        'seed': config_obj.training.seed,  # ü•© seed Ï†ïÎ≥¥ Ï†ÄÏû•
        
        # ü¶à ProxyAnchorLoss ÏÑ§Ï†ï Ï†ÄÏû•
        'proxy_anchor_config': {
            'enabled': config_obj.training.use_proxy_anchor,
            'margin': config_obj.training.proxy_margin,
            'alpha': config_obj.training.proxy_alpha,
            'lr_ratio': config_obj.training.proxy_lr_ratio,
            'lambda': config_obj.training.proxy_lambda
        } if hasattr(config_obj.training, 'use_proxy_anchor') and config_obj.training.use_proxy_anchor else None,
        
        # ‚≠êÔ∏è ÏóêÎÑàÏßÄ Ïä§ÏΩîÏñ¥ ÏÑ§Ï†ï Ï†ÄÏû•
        'energy_score_config': {
            'enabled': hasattr(config_obj.openset, 'score_mode') and config_obj.openset.score_mode == 'energy',
            'temperature': getattr(config_obj.training, 'energy_temperature', None),
            'k_mode': getattr(config_obj.training, 'energy_k_mode', None),
            'k_fixed': getattr(config_obj.training, 'energy_k_fixed', None)
        } if openset_enabled else None,
        
        # ü•© TTA ÏÑ§Ï†ï Ï†ÄÏû•
        'tta_config': {
            'enabled': config_obj.openset.tta_n_views > 1,
            'n_views': config_obj.openset.tta_n_views,
            'include_original': config_obj.openset.tta_include_original,
            'augmentation_strength': config_obj.openset.tta_augmentation_strength,
            'aggregation': config_obj.openset.tta_aggregation,
            'agree_k': config_obj.openset.tta_agree_k,
            
            # üéæ ÌÉÄÏûÖÎ≥Ñ Î∞òÎ≥µ ÏÑ§Ï†ï Ï∂îÍ∞Ä
            'n_repeats_genuine': config_obj.openset.tta_n_repeats_genuine,
            'n_repeats_between': config_obj.openset.tta_n_repeats_between,
            'n_repeats_negref': config_obj.openset.tta_n_repeats_negref,
            'repeat_aggregation': config_obj.openset.tta_repeat_aggregation
        } if openset_enabled else None,
        
        # üéæ Impostor ÎπÑÏú® ÏÑ§Ï†ï Ï†ÄÏû•
        'impostor_ratio_config': {
            'between': config_obj.openset.impostor_ratio_between,
            'unknown': config_obj.openset.impostor_ratio_unknown,
            'negref': config_obj.openset.impostor_ratio_negref,
            'total_samples': config_obj.openset.impostor_balance_total
        } if openset_enabled else None
    }
    
    # 8. Continual Learning ÏãúÏûë
    print("\n=== Starting Continual Learning ===")
    print(f"Total experiences: {config_obj.training.num_experiences}")
    print(f"Evaluation interval: every {config_obj.training.test_interval} users")
    print(f"üî• Negative warmup: exp0~{config_obj.negative.warmup_experiences-1}")
    print(f"Learning rate: {config_obj.training.learning_rate}")
    print(f"Memory batch size: {config_obj.training.memory_batch_size}")
    print(f"Temperature: {config_obj.training.temperature}")
    print(f"üé≤ Random seed: {config_obj.training.seed}")  # ü•© seed Ï∂úÎ†•
    
    start_time = time.time()
    
    for exp_id, (user_id, image_paths, labels) in enumerate(data_stream):
        
        # Experience ÌïôÏäµ
        stats = trainer.train_experience(user_id, image_paths, labels)
        training_history['losses'].append(stats['loss'])
        training_history['memory_sizes'].append(stats['memory_size'])
        
        # exp3‚Üíexp4 Í≤ΩÍ≥ÑÏóêÏÑú ÎÑ§Í±∞Ìã∞Î∏å ÏôÑÏ†Ñ Ï†úÍ±∞
        if exp_id + 1 == config_obj.negative.warmup_experiences:
            print(f"\nüî• === Warmup End (exp{exp_id}) ‚Üí Post-warmup (exp{exp_id+1}) ===")
            
            acc_pre, _ = evaluate_on_test_set(trainer, config_obj, openset_mode=openset_enabled)
            print(f"[Warmup-End] pre-purge ACC={acc_pre:.2f}%")
            
            purge_negatives(memory_buffer, config_obj.negative.base_id)
            trainer._update_ncm()
            
            acc_post, _ = evaluate_on_test_set(trainer, config_obj, openset_mode=openset_enabled)
            print(f"[Warmup-End] post-purge ACC={acc_post:.2f}%")
            print(f"üî• ========================================\n")
        
        # ÌèâÍ∞Ä Ï£ºÍ∏∞ ÌôïÏù∏
        if (exp_id + 1) % config_obj.training.test_interval == 0 or exp_id == config_obj.training.num_experiences - 1:
            
            print(f"\n=== Evaluation at Experience {exp_id + 1} ===")
            
            # t-SNE ÏãúÍ∞ÅÌôî
            if (exp_id + 1) % 10 == 0 or exp_id == config_obj.training.num_experiences - 1:
                tsne_dir = os.path.join(results_dir, "tsne")
                os.makedirs(tsne_dir, exist_ok=True)
                
                tsne_path = os.path.join(tsne_dir, f"tsne_exp_{exp_id+1:03d}.png")
                plot_tsne_from_memory(
                    trainer=trainer,
                    save_path=tsne_path,
                    per_class=150,
                    space='fe',
                    perplexity=30,
                    max_points=5000,
                    seed=42
                )
                
                if config_obj.model.use_projection:
                    tsne_path_z = os.path.join(tsne_dir, f"tsne_z_exp_{exp_id+1:03d}.png")
                    plot_tsne_from_memory(
                        trainer=trainer,
                        save_path=tsne_path_z,
                        per_class=150,
                        space='z',
                        perplexity=30,
                        max_points=5000,
                        seed=42
                    )
            
            # ÌÖåÏä§Ìä∏ÏÖãÏúºÎ°ú ÌèâÍ∞Ä
            accuracy, openset_metrics = evaluate_on_test_set(
                trainer, config_obj, 
                openset_mode=openset_enabled
            )
            
            # Î©îÌä∏Î¶≠ ÏóÖÎç∞Ïù¥Ìä∏
            evaluator.update(exp_id, accuracy)
            if openset_metrics:
                evaluator.update_openset(openset_metrics)
            
            # ÌèâÍ∑† Ï†ïÌôïÎèÑÏôÄ Forgetting Í≥ÑÏÇ∞
            avg_acc = evaluator.get_average_accuracy()
            forgetting = evaluator.get_forgetting_measure()
            
            # Í∏∞Î°ù Ï†ÄÏû•
            accuracy_record = {
                'experience': exp_id + 1,
                'accuracy': accuracy,
                'average_accuracy': avg_acc,
                'forgetting': forgetting
            }
            
            # Ïò§ÌîàÏÖã Î©îÌä∏Î¶≠ Ï∂îÍ∞Ä
            if openset_metrics:
                accuracy_record.update(openset_metrics)
                training_history['openset_metrics'].append(openset_metrics)
            
            training_history['accuracies'].append(accuracy_record)
            
            print(f"Test Accuracy: {accuracy:.2f}%")
            print(f"Average Accuracy: {avg_acc:.2f}%")
            print(f"Forgetting Measure: {forgetting:.2f}%")
            print(f"Memory Buffer Size: {len(memory_buffer)}")
            
            # Ïò§ÌîàÏÖã Î©îÌä∏Î¶≠ Ï∂úÎ†•
            if openset_metrics:
                print(f"\nüêã Open-set Metrics:")
                if 'TAR' in openset_metrics:
                    print(f"   TAR: {openset_metrics['TAR']:.3f}, FRR: {openset_metrics['FRR']:.3f}")
                if 'TRR_unknown' in openset_metrics:
                    print(f"   TRR_unknown: {openset_metrics['TRR_unknown']:.3f}, FAR_unknown: {openset_metrics['FAR_unknown']:.3f}")
                print(f"   œÑ_s: {openset_metrics.get('tau_s', 0):.4f}")
                
                # ü•© TTA Ï†ïÎ≥¥ Ï∂úÎ†•
                if openset_metrics.get('tta_enabled'):
                    print(f"   üéØ TTA: {openset_metrics.get('tta_views', 1)} views")
                    
                    # üéæ ÌÉÄÏûÖÎ≥Ñ Î∞òÎ≥µ Ï†ïÎ≥¥ Ï∂úÎ†•
                    print(f"   üîÑ Type-specific repeats:")
                    print(f"      Genuine: {openset_metrics.get('tta_repeats_genuine', 1)}")
                    print(f"      Between: {openset_metrics.get('tta_repeats_between', 1)}")
                    print(f"      NegRef: {openset_metrics.get('tta_repeats_negref', 1)}")
            
            # TrainerÏùò Ïò§ÌîàÏÖã ÌèâÍ∞Ä ÌûàÏä§ÌÜ†Î¶¨ÎèÑ Ï†ÄÏû•
            if hasattr(trainer, 'evaluation_history') and trainer.evaluation_history:
                training_history['trainer_openset_history'] = trainer.evaluation_history
            
            # Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Ï†ÄÏû•
            checkpoint_path = os.path.join(
                results_dir, 
                f'checkpoint_exp_{exp_id + 1}.pth'
            )
            trainer.save_checkpoint(checkpoint_path)
            
        # ÏßÑÌñâ ÏÉÅÌô© Ï∂úÎ†•
        if (exp_id + 1) % 10 == 0:
            elapsed = time.time() - start_time
            eta = elapsed / (exp_id + 1) * (config_obj.training.num_experiences - exp_id - 1)
            print(f"Progress: {exp_id + 1}/{config_obj.training.num_experiences} "
                  f"({100 * (exp_id + 1) / config_obj.training.num_experiences:.1f}%) "
                  f"| Elapsed: {elapsed/60:.1f}m | ETA: {eta/60:.1f}m")
    
    # 9. ÏµúÏ¢Ö Í≤∞Í≥º Ï†ÄÏû•
    print("\n=== Saving Final Results ===")
    
    # ÌïôÏäµ Í∏∞Î°ù Ï†ÄÏû•
    history_path = os.path.join(results_dir, 'training_history.json')
    with open(history_path, 'w') as f:
        json.dump(training_history, f, indent=4)
    
    # t-SNE ÏãúÍ∞ÅÌôî Í≤ΩÎ°ú Ï∂îÍ∞Ä
    tsne_images = []
    tsne_dir = os.path.join(results_dir, "tsne")
    if os.path.exists(tsne_dir):
        tsne_images = sorted([f for f in os.listdir(tsne_dir) if f.endswith('.png')])
        if tsne_images:
            print(f"\nüé® t-SNE visualizations saved: {len(tsne_images)} images")
            print(f"   Location: {tsne_dir}")
    
    # ÏµúÏ¢Ö ÌÜµÍ≥Ñ
    final_result = training_history['accuracies'][-1] if training_history['accuracies'] else {}
    final_acc = final_result.get('accuracy', 0)
    final_avg_acc = final_result.get('average_accuracy', 0)
    final_forget = final_result.get('forgetting', 0)
    
    print(f"\n=== Final Results ===")
    print(f"Final Test Accuracy: {final_acc:.2f}%")
    print(f"Final Average Accuracy: {final_avg_acc:.2f}%")
    print(f"Final Forgetting Measure: {final_forget:.2f}%")
    
    # ü¶à ProxyAnchorLoss ÏµúÏ¢Ö Ï†ïÎ≥¥
    if hasattr(config_obj.training, 'use_proxy_anchor') and config_obj.training.use_proxy_anchor:
        print(f"\nü¶à Proxy Anchor Loss Configuration:")
        print(f"   Margin: {config_obj.training.proxy_margin}")
        print(f"   Alpha: {config_obj.training.proxy_alpha}")
        print(f"   Lambda: {config_obj.training.proxy_lambda}")
    
    # ÏµúÏ¢Ö Ïò§ÌîàÏÖã Î©îÌä∏Î¶≠
    if openset_enabled and 'TAR' in final_result:
        print(f"\nüêã Final Open-set Performance:")
        print(f"   TAR: {final_result.get('TAR', 0):.3f}")
        print(f"   TRR (Unknown): {final_result.get('TRR_unknown', 0):.3f}")
        print(f"   FAR (Unknown): {final_result.get('FAR_unknown', 0):.3f}")
        print(f"   Final œÑ_s: {final_result.get('tau_s', 0):.4f}")
        
        # ü•© TTA ÏµúÏ¢Ö Ï†ïÎ≥¥
        if final_result.get('tta_enabled'):
            print(f"   üéØ TTA: Enabled ({final_result.get('tta_views', 1)} views)")
            
            # üéæ ÌÉÄÏûÖÎ≥Ñ Î∞òÎ≥µ ÏµúÏ¢Ö Ï†ïÎ≥¥
            print(f"   üîÑ Type-specific Repeats:")
            print(f"      Genuine: {final_result.get('tta_repeats_genuine', 1)}")
            print(f"      Between: {final_result.get('tta_repeats_between', 1)}")
            print(f"      NegRef: {final_result.get('tta_repeats_negref', 1)}")
            print(f"      Aggregation: {final_result.get('tta_repeat_aggregation', 'median')}")
    
    print(f"\nTotal Training Time: {(time.time() - start_time)/60:.1f} minutes")
    
    # Í≤∞Í≥º ÏöîÏïΩ Ï†ÄÏû•
    summary = {
        'config': args.config,
        'num_experiences': config_obj.training.num_experiences,
        'memory_size': config_obj.training.memory_size,
        'final_accuracy': final_acc,
        'final_average_accuracy': final_avg_acc,
        'final_forgetting': final_forget,
        'total_time_minutes': (time.time() - start_time) / 60,
        'negative_removal_history': training_history['negative_removal_history'],
        'openset_enabled': openset_enabled,
        'seed': config_obj.training.seed,  # ü•© seed Ï†ÄÏû•
        
        # ü¶à ProxyAnchorLoss ÏÑ§Ï†ï Ï∂îÍ∞Ä
        'proxy_anchor_config': {
            'enabled': config_obj.training.use_proxy_anchor,
            'margin': config_obj.training.proxy_margin,
            'alpha': config_obj.training.proxy_alpha,
            'lr_ratio': config_obj.training.proxy_lr_ratio,
            'lambda': config_obj.training.proxy_lambda
        } if hasattr(config_obj.training, 'use_proxy_anchor') and config_obj.training.use_proxy_anchor else None
    }
    
    # Ïò§ÌîàÏÖã ÏöîÏïΩ Ï∂îÍ∞Ä
    if openset_enabled and final_result:
        summary['final_openset'] = {
            'TAR': final_result.get('TAR', 0),
            'TRR_unknown': final_result.get('TRR_unknown', 0),
            'FAR_unknown': final_result.get('FAR_unknown', 0),
            'tau_s': final_result.get('tau_s', 0),
            'score_mode': final_result.get('score_mode', 'max'),
            'tta_enabled': final_result.get('tta_enabled', False)  # ü•© TTA Ï∂îÍ∞Ä
        }
        
        # ü•© TTA ÏÑ§Ï†ï Ï∂îÍ∞Ä
        if final_result.get('tta_enabled'):
            summary['final_openset']['tta_config'] = {
                'n_views': final_result.get('tta_views', 1),
                'aggregation': config_obj.openset.tta_aggregation,
                
                # üéæ ÌÉÄÏûÖÎ≥Ñ Î∞òÎ≥µ ÏÑ§Ï†ï Ï∂îÍ∞Ä
                'n_repeats_genuine': final_result.get('tta_repeats_genuine', 1),
                'n_repeats_between': final_result.get('tta_repeats_between', 1),
                'n_repeats_negref': final_result.get('tta_repeats_negref', 1),
                'repeat_aggregation': final_result.get('tta_repeat_aggregation', 'median')
            }
        
        # üéæ Impostor ÎπÑÏú® ÏÑ§Ï†ï Ï∂îÍ∞Ä
        summary['final_openset']['impostor_ratios'] = {
            'between': config_obj.openset.impostor_ratio_between,
            'unknown': config_obj.openset.impostor_ratio_unknown,
            'negref': config_obj.openset.impostor_ratio_negref,
            'total_samples': config_obj.openset.impostor_balance_total
        }
    
    summary_path = os.path.join(results_dir, 'summary.json')
    with open(summary_path, 'w') as f:
        json.dump(summary, f, indent=4)
    
    print(f"\nResults saved to: {results_dir}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='SCR Training with ProxyAnchorLoss, Energy Score & TTA Support')
    parser.add_argument('--config', type=str, default='config/config.yaml',
                        help='Path to config file')
    parser.add_argument('--seed', type=int, default=42,
                        help='Random seed')
    parser.add_argument('--no-cuda', action='store_true',
                        help='Disable CUDA')
    
    args = parser.parse_args()
    main(args)