# ğŸŒ• Avalancheì˜ ncm_classifier.py ê¸°ë°˜

from typing import Dict
import torch
from torch import Tensor, nn


class NCMClassifier(nn.Module):  # ğŸŒ• Avalanche ê¸°ë°˜ (DynamicModule ì˜ì¡´ì„±ë§Œ ì œê±°)
    """
    NCM (Nearest Class Mean) Classifier.
    
    ê° í´ë˜ìŠ¤ì˜ í‰ê·  feature vector (prototype)ë¥¼ ì €ì¥í•˜ê³ ,
    ìƒˆë¡œìš´ ì…ë ¥ì´ ë“¤ì–´ì˜¤ë©´ ê°€ì¥ ê°€ê¹Œìš´ í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    
    ğŸŒ• Avalancheì˜ NCMClassifierë¥¼ ìµœëŒ€í•œ ìœ ì§€
    """

    def __init__(self, normalize: bool = True):
        """
        :param normalize: ì…ë ¥ì„ L2 ì •ê·œí™”í• ì§€ ì—¬ë¶€.
                         Trueë©´ cosine similarity ê¸°ë°˜ ë¶„ë¥˜
                         Falseë©´ Euclidean distance ê¸°ë°˜ ë¶„ë¥˜
        """
        super().__init__()
        # ğŸŒ• Avalancheì™€ ë™ì¼í•œ êµ¬ì¡°
        self.register_buffer("class_means", None)  # [num_classes, feature_size]
        self.class_means_dict = {}  # {class_id: mean_vector}
        
        self.normalize = normalize
        self.max_class = -1

    def load_state_dict(self, state_dict, strict: bool = True):  # ğŸŒ• Avalanche ê·¸ëŒ€ë¡œ
        """
        ì²´í¬í¬ì¸íŠ¸ì—ì„œ ìƒíƒœë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
        í´ë˜ìŠ¤ í‰ê· ì„ ë³µì›í•˜ëŠ” ë° í•„ìˆ˜ì ì…ë‹ˆë‹¤.
        """
        self.class_means = state_dict["class_means"]
        super().load_state_dict(state_dict, strict)
        # í…ì„œì—ì„œ ë”•ì…”ë„ˆë¦¬ ì¬êµ¬ì„±
        if self.class_means is not None:
            for i in range(self.class_means.shape[0]):
                if (self.class_means[i] != 0).any():
                    self.class_means_dict[i] = self.class_means[i].clone()
        self.max_class = max(self.class_means_dict.keys()) if self.class_means_dict else -1

    def _vectorize_means_dict(self):  # ğŸŒ• Avalanche ê·¸ëŒ€ë¡œ
        """
        ë”•ì…”ë„ˆë¦¬ í˜•íƒœì˜ class meansë¥¼ í…ì„œë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        ë¹ ë¥¸ ê±°ë¦¬ ê³„ì‚°ì„ ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤.
        """
        if self.class_means_dict == {}:
            return

        max_class = max(self.class_means_dict.keys())
        self.max_class = max(max_class, self.max_class)
        
        # ì²« ë²ˆì§¸ mean vectorë¡œ feature ì°¨ì› í™•ì¸
        first_mean = list(self.class_means_dict.values())[0]
        feature_size = first_mean.size(0)
        device = first_mean.device
        
        # ëª¨ë“  í´ë˜ìŠ¤ë¥¼ ë‹´ì„ ìˆ˜ ìˆëŠ” í…ì„œ ìƒì„±
        self.class_means = torch.zeros(self.max_class + 1, feature_size).to(device)

        # ë”•ì…”ë„ˆë¦¬ì—ì„œ í…ì„œë¡œ ë³µì‚¬
        for k, v in self.class_means_dict.items():
            self.class_means[k] = self.class_means_dict[k].clone()

    @torch.no_grad()
    def forward(self, x):  # ğŸŒ• Avalanche ê·¸ëŒ€ë¡œ
        """
        ì…ë ¥ xì— ëŒ€í•´ ê° í´ë˜ìŠ¤ê¹Œì§€ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        :param x: (batch_size, feature_size)
        :return: (batch_size, num_classes) - ê° í´ë˜ìŠ¤ê¹Œì§€ì˜ negative distance
        """
        if self.class_means_dict == {}:
            # ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš° ì²˜ë¦¬
            self.init_missing_classes(range(self.max_class + 1), x.shape[1], x.device)

        assert self.class_means_dict != {}, "no class means available."
        
        if self.normalize:
            # L2 ì •ê·œí™” (cosine similarityë¥¼ ìœ„í•´)
            x = torch.nn.functional.normalize(x, p=2, dim=1)

        # ëª¨ë“  í´ë˜ìŠ¤ í‰ê· ê³¼ì˜ ê±°ë¦¬ ê³„ì‚°
        # (num_classes, batch_size)
        sqd = torch.cdist(self.class_means.to(x.device), x)
        
        # negative distance ë°˜í™˜ (ê°’ì´ í´ìˆ˜ë¡ ê°€ê¹Œì›€)
        # (batch_size, num_classes)
        return (-sqd).T

    def update_class_means_dict(
        self, class_means_dict: Dict[int, Tensor], momentum: float = 0.5  # ğŸŒ• Avalanche ê¸°ë³¸ê°’
    ):
        """
        í´ë˜ìŠ¤ í‰ê· ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        
        ğŸŒ• Avalancheì˜ ê¸°ë³¸ê°’ 0.5 ìœ ì§€
        - momentum = 0.5: ì´ì „ ì§€ì‹ê³¼ ìƒˆ ì§€ì‹ì„ ë™ë“±í•˜ê²Œ ê°€ì¤‘
        - momentum = 1.0: ì™„ì „ êµì²´ (ì´ì „ ì§€ì‹ ë¬´ì‹œ)
        - momentum = 0.0: ì—…ë°ì´íŠ¸ ì•ˆí•¨ (ìƒˆ ì§€ì‹ ë¬´ì‹œ)
        
        Continual learningì—ì„œëŠ” 0.5ê°€ catastrophic forgettingì„
        ì™„í™”í•˜ëŠ” ë° íš¨ê³¼ì ì…ë‹ˆë‹¤.
        
        :param class_means_dict: {í´ë˜ìŠ¤ ID: í‰ê·  ë²¡í„°} ë”•ì…”ë„ˆë¦¬
        :param momentum: ìƒˆë¡œìš´ í‰ê· ì˜ ê°€ì¤‘ì¹˜ (0.0 ~ 1.0)
        """
        assert momentum <= 1 and momentum >= 0
        assert isinstance(class_means_dict, dict), (
            "class_means_dict must be a dictionary mapping class_id " "to mean vector"
        )
        
        for k, v in class_means_dict.items():
            if k not in self.class_means_dict or (self.class_means_dict[k] == 0).all():
                # ìƒˆë¡œìš´ í´ë˜ìŠ¤
                self.class_means_dict[k] = class_means_dict[k].clone()
            else:
                # ê¸°ì¡´ í´ë˜ìŠ¤ ì—…ë°ì´íŠ¸ (momentum ì ìš©)
                device = self.class_means_dict[k].device
                self.class_means_dict[k] = (
                    momentum * class_means_dict[k].to(device)
                    + (1 - momentum) * self.class_means_dict[k]
                )

        self._vectorize_means_dict()

    def replace_class_means_dict(self, class_means_dict: Dict[int, Tensor]):  # ğŸŒ• Avalanche ê·¸ëŒ€ë¡œ
        """
        ê¸°ì¡´ í‰ê· ì„ ì™„ì „íˆ êµì²´í•©ë‹ˆë‹¤.
        momentum = 1.0ê³¼ ë™ì¼í•œ íš¨ê³¼ì…ë‹ˆë‹¤.
        """
        assert isinstance(class_means_dict, dict), (
            "class_means_dict must be a dictionary mapping class_id " "to mean vector"
        )
        self.class_means_dict = {k: v.clone() for k, v in class_means_dict.items()}
        self._vectorize_means_dict()

    def init_missing_classes(self, classes, class_size, device):  # ğŸŒ• Avalanche ê·¸ëŒ€ë¡œ
        """
        ì•„ì§ í‰ê· ì´ ì—†ëŠ” í´ë˜ìŠ¤ë¥¼ 0 ë²¡í„°ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        """
        for k in classes:
            if k not in self.class_means_dict:
                self.class_means_dict[k] = torch.zeros(class_size).to(device)
        self._vectorize_means_dict()

    def adaptation(self, experience):  # ğŸŒ• Avalancheì˜ adaptation (ë‹¨ìˆœí™”)
        """
        ìƒˆë¡œìš´ experienceì— ë§ì¶° ëª¨ë¸ì„ ì ì‘ì‹œí‚µë‹ˆë‹¤.
        
        ìƒˆë¡œìš´ í´ë˜ìŠ¤ê°€ ë‚˜íƒ€ë‚˜ë©´ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        :param experience: í˜„ì¬ experience (classes_in_this_experience í•„ìš”)
        """
        # ğŸ”„ DynamicModuleì˜ super().adaptation() ì œê±°
        
        if hasattr(experience, 'classes_in_this_experience'):
            classes = experience.classes_in_this_experience
            for k in classes:
                self.max_class = max(k, self.max_class)
            
            if self.class_means is not None:
                self.init_missing_classes(
                    classes, self.class_means.shape[1], self.class_means.device
                )
    
    # ğŸ£ ì¶”ê°€ í¸ì˜ ë©”ì„œë“œë“¤
    def predict(self, x):
        """
        ì‹¤ì œ í´ë˜ìŠ¤ ì˜ˆì¸¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        :param x: (batch_size, feature_size)
        :return: (batch_size,) - ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ID
        """
        scores = self.forward(x)  # (batch_size, num_classes)
        return scores.argmax(dim=1)
    
    def get_num_classes(self):
        """í˜„ì¬ ì €ì¥ëœ í´ë˜ìŠ¤ ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return len(self.class_means_dict)
    
    def get_class_means(self):
        """í˜„ì¬ ì €ì¥ëœ í´ë˜ìŠ¤ í‰ê· ë“¤ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return self.class_means_dict.copy()


# ğŸ£ í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    # NCM Classifier í…ŒìŠ¤íŠ¸
    ncm = NCMClassifier(normalize=True)
    
    # ê°€ìƒì˜ í´ë˜ìŠ¤ í‰ê·  ì„¤ì •
    class_means = {
        0: torch.randn(128).float(),  # í´ë˜ìŠ¤ 0ì˜ í‰ê· 
        1: torch.randn(128).float(),  # í´ë˜ìŠ¤ 1ì˜ í‰ê· 
    }
    
    # momentum í…ŒìŠ¤íŠ¸
    print("=== Momentum í…ŒìŠ¤íŠ¸ ===")
    ncm.update_class_means_dict(class_means, momentum=0.5)  # ê¸°ë³¸ê°’
    
    # ê°™ì€ í´ë˜ìŠ¤ì— ìƒˆë¡œìš´ í‰ê·  ì—…ë°ì´íŠ¸
    new_means = {
        0: torch.randn(128).float(),  # í´ë˜ìŠ¤ 0ì˜ ìƒˆ í‰ê· 
    }
    ncm.update_class_means_dict(new_means, momentum=0.3)  # 30%ë§Œ ë°˜ì˜
    
    # í…ŒìŠ¤íŠ¸ ì…ë ¥
    test_input = torch.randn(5, 128)  # 5ê°œ ìƒ˜í”Œ, 128ì°¨ì›
    
    # ì˜ˆì¸¡
    predictions = ncm.predict(test_input)
    print(f"Predictions: {predictions}")
    print(f"Number of classes: {ncm.get_num_classes()}")