# utils/pretrained_loader.py (ê°„ì†Œí™”)
import torch
import torch.nn as nn
from pathlib import Path

class PretrainedLoader:
    """CCNet ì‚¬ì „í›ˆë ¨ ëª¨ë¸ ë¡œë” (ArcLayer ì œê±° ë²„ì „)"""
    
    @staticmethod
    def load_ccnet_pretrained(
        model: nn.Module, 
        checkpoint_path: Path,
        device: str = 'cuda',
        verbose: bool = True
    ) -> nn.Module:
        """
        ArcLayerê°€ ì œê±°ëœ CCNet ì‚¬ì „í›ˆë ¨ ê°€ì¤‘ì¹˜ ë¡œë“œ
        """
        print("\n" + "="*60)
        print("ğŸ”¥ Loading Pretrained CCNet (No ArcLayer)")
        print("="*60)
        print(f"ğŸ“ Path: {checkpoint_path}")
        
        if not checkpoint_path.exists():
            raise FileNotFoundError(f"Checkpoint not found: {checkpoint_path}")
        
        # 1. ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        checkpoint = torch.load(checkpoint_path, map_location=device)
        
        # 2. state_dict ì¶”ì¶œ
        if isinstance(checkpoint, dict):
            # ì—¬ëŸ¬ í˜•íƒœ ì§€ì›
            if 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
            elif 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            elif 'model' in checkpoint:
                state_dict = checkpoint['model']
            else:
                state_dict = checkpoint
        else:
            state_dict = checkpoint
        
        # 3. í˜„ì¬ ëª¨ë¸ì˜ state_dict
        model_dict = model.state_dict()
        
        # 4. ë§¤ì¹­ë˜ëŠ” ë ˆì´ì–´ë§Œ ë¡œë“œ
        loaded = {}
        skipped = []
        
        for name, param in state_dict.items():
            # DataParallel prefix ì œê±°
            name = name.replace('module.', '')
            
            # ArcLayer ê±´ë„ˆë›°ê¸° (í˜¹ì‹œ ìˆë‹¤ë©´)
            if 'arc' in name.lower() or 'classifier' in name:
                skipped.append(name)
                continue
            
            # ë§¤ì¹­ë˜ëŠ” ë ˆì´ì–´ë§Œ ë¡œë“œ
            if name in model_dict:
                if model_dict[name].shape == param.shape:
                    loaded[name] = param
                    if verbose:
                        print(f"  âœ… {name}")
                else:
                    skipped.append(f"{name} (shape mismatch)")
            else:
                skipped.append(f"{name} (not found)")
        
        # 5. í†µê³„ ì¶œë ¥
        print(f"\nğŸ“Š Loaded: {len(loaded)}/{len(state_dict)} layers")
        if skipped and verbose:
            print(f"âš ï¸  Skipped: {len(skipped)} layers")
        
        # 6. ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
        model_dict.update(loaded)
        model.load_state_dict(model_dict, strict=False)
        
        print("âœ… Pretrained weights loaded successfully!\n")
        print("="*60 + "\n")
        
        return model