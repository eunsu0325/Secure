# ğŸ‹ scr/utils_openset.py (ì‹ ê·œ)
"""ì˜¤í”ˆì…‹ ê´€ë ¨ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤"""

import numpy as np
import torch
import torch.nn.functional as F
from PIL import Image
from typing import List, Tuple, Set
import os
from collections import defaultdict


def split_user_data(paths: List[str], labels: List[int], 
                   dev_ratio: float = 0.2, min_dev: int = 2) -> Tuple:
    """ì‚¬ìš©ì ë°ì´í„°ë¥¼ Train/Devë¡œ ë¶„ë¦¬"""
    idx = np.arange(len(paths))
    np.random.shuffle(idx)
    n_dev = max(min_dev, int(len(paths) * dev_ratio))
    
    dev_idx = idx[:n_dev]
    train_idx = idx[n_dev:]
    
    train_paths = [paths[i] for i in train_idx]
    train_labels = [labels[i] for i in train_idx]
    dev_paths = [paths[i] for i in dev_idx]
    dev_labels = [labels[i] for i in dev_idx]
    
    return train_paths, train_labels, dev_paths, dev_labels


def load_paths_labels_from_txt(txt_file: str) -> Tuple[List[str], List[int]]:
    """txt íŒŒì¼ì—ì„œ ê²½ë¡œì™€ ë ˆì´ë¸” ì½ê¸°"""
    paths, labels = [], []
    if not os.path.exists(txt_file):
        return paths, labels
        
    with open(txt_file, 'r') as f:
        for line in f:
            parts = line.strip().split(' ')
            if len(parts) == 2:
                paths.append(parts[0])
                labels.append(int(parts[1]))
    return paths, labels


def load_paths_labels_excluding(txt_file: str, exclude_labels: Set[int]) -> Tuple[List[str], List[int]]:
    """íŠ¹ì • ë ˆì´ë¸”ì„ ì œì™¸í•˜ê³  ë¡œë“œ"""
    all_paths, all_labels = load_paths_labels_from_txt(txt_file)
    paths, labels = [], []
    
    for p, l in zip(all_paths, all_labels):
        if l not in exclude_labels:
            paths.append(p)
            labels.append(l)
    
    return paths, labels


@torch.no_grad()
def extract_features(model, paths: List[str], transform, device, batch_size: int = 64) -> np.ndarray:
    """ì´ë¯¸ì§€ ê²½ë¡œì—ì„œ íŠ¹ì§• ì¶”ì¶œ"""
    if not paths:
        return np.array([])
        
    feats = []
    model.eval()
    
    for i in range(0, len(paths), batch_size):
        batch = []
        for p in paths[i:i+batch_size]:
            img = Image.open(p).convert('L')
            img = transform(img)
            batch.append(img)
        
        x = torch.stack(batch, dim=0).to(device)
        f = model.getFeatureCode(x)  # (B, D)
        f = F.normalize(f, p=2, dim=1)  # ì½”ì‚¬ì¸ìš© ì •ê·œí™”
        feats.append(f.cpu())
    
    return torch.cat(feats, dim=0).numpy() if feats else np.array([])


def extract_scores_genuine(model, ncm, dev_paths: List[str], dev_labels: List[int],
                          transform, device) -> np.ndarray:
    """ê°™ì€ í´ë˜ìŠ¤ ë‚´ genuine ì ìˆ˜"""
    by_class = defaultdict(list)
    for p, y in zip(dev_paths, dev_labels):
        by_class[int(y)].append(p)
    
    scores = []
    for cls_id, cls_paths in by_class.items():
        if len(cls_paths) < 2:
            continue
            
        # í´ë˜ìŠ¤ì˜ í”„ë¡œí† íƒ€ì…ì´ ìˆëŠ”ì§€ í™•ì¸
        if cls_id not in ncm.class_means_dict:
            continue
            
        # íŠ¹ì§• ì¶”ì¶œ
        feats = extract_features(model, cls_paths, transform, device)
        
        # ê°™ì€ í´ë˜ìŠ¤ ë‚´ í˜ì–´ ì ìˆ˜
        for i in range(len(feats)):
            for j in range(i+1, len(feats)):
                score = (feats[i] @ feats[j]).item()
                scores.append(score)
    
    return np.array(scores)


def extract_scores_impostor_between(model, ncm, dev_paths: List[str], dev_labels: List[int],
                                   transform, device, max_pairs: int = 2000) -> np.ndarray:
    """ë‹¤ë¥¸ í´ë˜ìŠ¤ ê°„ impostor ì ìˆ˜"""
    by_class = defaultdict(list)
    for p, y in zip(dev_paths, dev_labels):
        by_class[int(y)].append(p)
    
    class_ids = list(by_class.keys())
    scores = []
    
    for i in range(len(class_ids)):
        for j in range(i+1, len(class_ids)):
            if len(scores) >= max_pairs:
                break
                
            # ê° í´ë˜ìŠ¤ì—ì„œ ì²« ìƒ˜í”Œë§Œ
            path_i = by_class[class_ids[i]][0]
            path_j = by_class[class_ids[j]][0]
            
            feat_i = extract_features(model, [path_i], transform, device)
            feat_j = extract_features(model, [path_j], transform, device)
            
            score = (feat_i @ feat_j.T).item()
            scores.append(score)
    
    return np.array(scores)


def extract_scores_impostor_unknown(model, ncm, txt_file: str, registered_users: Set[int],
                                   transform, device, max_eval: int = 3000) -> np.ndarray:
    """ë¯¸ë“±ë¡ ì‚¬ìš©ìì˜ impostor ì ìˆ˜"""
    paths, labels = load_paths_labels_excluding(txt_file, registered_users)
    
    if not paths:
        return np.array([])
    
    # ìƒ˜í”Œë§
    if len(paths) > max_eval:
        idx = np.random.choice(len(paths), max_eval, replace=False)
        paths = [paths[i] for i in idx]
    
    # íŠ¹ì§• ì¶”ì¶œ
    feats = extract_features(model, paths, transform, device)
    
    # í”„ë¡œí† íƒ€ì…ê³¼ì˜ ìµœëŒ€ ìœ ì‚¬ë„
    if not ncm.class_means_dict:
        return np.array([])
    
    protos = []
    for cid, mu in ncm.class_means_dict.items():
        protos.append(mu.cpu().numpy())
    
    P = np.stack(protos, axis=0)  # (C, D)
    scores = (feats @ P.T).max(axis=1)  # ê° unknownì˜ ìµœëŒ€ ë§¤ì¹­
    
    return scores


def extract_scores_impostor_negref(model, ncm, negref_file: str, transform, device,
                                  max_eval: int = 5000) -> np.ndarray:
    """NegRefì˜ impostor ì ìˆ˜"""
    if not negref_file or not os.path.exists(negref_file):
        return np.array([])
    
    paths, labels = load_paths_labels_from_txt(negref_file)
    
    if not paths:
        return np.array([])
    
    # ìƒ˜í”Œë§
    if len(paths) > max_eval:
        idx = np.random.choice(len(paths), max_eval, replace=False)
        paths = [paths[i] for i in idx]
    
    # íŠ¹ì§• ì¶”ì¶œ
    feats = extract_features(model, paths, transform, device)
    
    # í”„ë¡œí† íƒ€ì…ê³¼ì˜ ìµœëŒ€ ìœ ì‚¬ë„
    if not ncm.class_means_dict:
        return np.array([])
    
    protos = []
    for cid, mu in ncm.class_means_dict.items():
        protos.append(mu.cpu().numpy())
    
    P = np.stack(protos, axis=0)
    scores = (feats @ P.T).max(axis=1)
    
    return scores


def balance_impostor_scores(s_between: np.ndarray, s_unknown: np.ndarray, s_negref: np.ndarray,
                           ratio: Tuple[float, float, float] = (0.2, 0.5, 0.3),
                           total: int = 4000) -> np.ndarray:
    """impostor ì ìˆ˜ ê· í˜• ë§ì¶”ê¸°"""
    pools = [np.asarray(s_between), np.asarray(s_unknown), np.asarray(s_negref)]
    want = [int(total * r) for r in ratio]
    out = []
    
    for arr, k in zip(pools, want):
        if arr.size == 0:
            continue
        if arr.size <= k:
            out.append(arr)
        else:
            out.append(np.random.choice(arr, k, replace=False))
    
    if not out:
        return np.array([])
    
    return np.concatenate(out)


@torch.no_grad()
def predict_batch(model, ncm, paths: List[str], transform, device, batch_size: int = 128) -> np.ndarray:
    """ë°°ì¹˜ ì˜ˆì¸¡"""
    if not paths:
        return np.array([])
    
    model.eval()
    preds = []
    
    for i in range(0, len(paths), batch_size):
        batch = []
        for p in paths[i:i+batch_size]:
            img = Image.open(p).convert('L')
            img = transform(img)
            batch.append(img)
        
        x = torch.stack(batch, dim=0).to(device)
        feat = model.getFeatureCode(x)
        pred = ncm.predict_openset(feat)
        preds.extend(pred.cpu().numpy())
    
    return np.array(preds)